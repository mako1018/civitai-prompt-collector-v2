#!/usr/bin/env python3
"""
Keyword-based Target Collection for Comprehensive NSFW Collection
ç‰¹å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åé›†æˆ¦ç•¥
"""

import requests
import time
from typing import List, Dict, Any
from collections import defaultdict

class KeywordTargetCollector:
    """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåé›†"""

    def __init__(self):
        # æ—¥æœ¬èªãƒ»ã‚¢ãƒ‹ãƒ¡ç³»ã‚¨ãƒ­ãƒ†ã‚£ãƒƒã‚¯è¡¨ç¾
        self.japanese_erotic = [
            'ahegao', 'paizuri', 'nakadashi', 'bukkake', 'gokkun',
            'shibari', 'kinbaku', 'futanari', 'yuri', 'yaoi',
            'tentacle', 'monster girl', 'catgirl', 'bunny girl',
            'schoolgirl', 'office lady', 'maid', 'nurse'
        ]

        # å¦Šå¨ ãƒ»æ¯ä¹³ç³»
        self.pregnancy_lactation = [
            'pregnant', 'pregnancy', 'belly', 'gravid', 'expecting',
            'lactation', 'breast milk', 'nursing', 'milking',
            'swollen breasts', 'milk drip', 'maternal'
        ]

        # å¹´é½¢ãƒ»ä½“å‹é–¢é€£
        self.age_body_types = [
            'milf', 'mature', 'cougar', 'older woman', 'mom',
            'teen', 'young', 'petite', 'slim', 'skinny',
            'thicc', 'chubby', 'bbw', 'curvy', 'voluptuous',
            'athletic', 'muscular', 'fit', 'toned'
        ]

        # ãƒ¬ã‚ºãƒ“ã‚¢ãƒ³ãƒ»ãƒã‚¤ã‚»ã‚¯ã‚·ãƒ£ãƒ«
        self.lesbian_content = [
            'lesbian', 'girl on girl', 'women kissing', 'tribbing',
            'scissoring', 'lesbian oral', 'strap-on lesbian',
            'girl love', 'sapphic', 'wlw', 'bisexual'
        ]

        # ã‚°ãƒ«ãƒ¼ãƒ—ã‚»ãƒƒã‚¯ã‚¹ãƒ»ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ¼
        self.group_activities = [
            'orgy', 'group sex', 'gangbang', 'train', 'bukkake party',
            'swinger', 'swapping', 'wife sharing', 'cuckold',
            'threesome ffm', 'threesome mmf', 'foursome', 'fivesome'
        ]

        # BDSMè©³ç´°
        self.bdsm_detailed = [
            'rope bondage', 'shibari', 'suspension', 'hogtied',
            'spreader bar', 'stocks', 'pillory', 'chastity',
            'orgasm denial', 'edging', 'forced orgasm', 'overstim',
            'impact play', 'spanking', 'paddling', 'caning',
            'needle play', 'wax play', 'electro', 'tens'
        ]

        # ç‰¹æ®Šãƒ•ã‚§ãƒ
        self.special_fetishes = [
            'feet', 'foot fetish', 'toe sucking', 'footjob',
            'armpit', 'belly button', 'navel', 'ear licking',
            'hair fetish', 'long hair', 'ponytail', 'braids',
            'glasses', 'stockings', 'pantyhose', 'high heels'
        ]

    def get_comprehensive_keywords(self) -> Dict[str, List[str]]:
        """åŒ…æ‹¬çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚»ãƒƒãƒˆã‚’è¿”ã™"""
        return {
            'japanese_erotic': self.japanese_erotic,
            'pregnancy_lactation': self.pregnancy_lactation,
            'age_body_types': self.age_body_types,
            'lesbian_content': self.lesbian_content,
            'group_activities': self.group_activities,
            'bdsm_detailed': self.bdsm_detailed,
            'special_fetishes': self.special_fetishes
        }

    def search_by_keywords(self, keywords: List[str], model_id: str = None, version_id: str = None,
                          nsfw_level: str = "X", max_per_keyword: int = 50) -> Dict[str, Any]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ¤œç´¢åé›†"""

        results = {
            'keyword_results': {},
            'total_found': 0,
            'unique_prompts': set(),
            'errors': []
        }

        from src.config import USER_AGENT, REQUEST_TIMEOUT, CIVITAI_API_KEY
        headers = {"User-Agent": USER_AGENT}
        if CIVITAI_API_KEY:
            headers['Authorization'] = f"Bearer {CIVITAI_API_KEY}"

        for keyword in keywords:
            try:
                # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                params = {
                    'limit': max_per_keyword,
                    'nsfw': nsfw_level,
                    'sort': 'Most Reactions',
                    'query': keyword  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
                }

                # ãƒ¢ãƒ‡ãƒ«/ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®š
                if version_id:
                    params['modelVersionId'] = version_id
                elif model_id:
                    params['modelId'] = model_id

                response = requests.get(
                    "https://civitai.com/api/v1/images",
                    params=params,
                    headers=headers,
                    timeout=REQUEST_TIMEOUT
                )

                if response.status_code == 200:
                    data = response.json()
                    items = data.get('items', [])

                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã®ç¢ºèª
                    relevant_items = []
                    for item in items:
                        prompt = item.get('meta', {}).get('prompt', '').lower()
                        if keyword.lower() in prompt:
                            relevant_items.append(item)
                            results['unique_prompts'].add(prompt[:200])  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨

                    results['keyword_results'][keyword] = {
                        'found_count': len(relevant_items),
                        'total_retrieved': len(items),
                        'items': relevant_items
                    }

                    results['total_found'] += len(relevant_items)

                else:
                    results['errors'].append(f"{keyword}: HTTP {response.status_code}")

                # APIåˆ¶é™å¯¾ç­–
                time.sleep(0.5)

            except Exception as e:
                results['errors'].append(f"{keyword}: {str(e)}")

        return results

    def analyze_coverage_gaps(self, existing_keywords: List[str]) -> Dict[str, List[str]]:
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚®ãƒ£ãƒƒãƒ—åˆ†æ"""

        all_categories = self.get_comprehensive_keywords()
        gaps = {}

        existing_lower = [kw.lower() for kw in existing_keywords]

        for category, keywords in all_categories.items():
            missing = []
            for keyword in keywords:
                if keyword.lower() not in existing_lower:
                    missing.append(keyword)

            if missing:
                gaps[category] = missing

        return gaps

    def recommend_collection_targets(self, model_analysis: Dict) -> Dict[str, Any]:
        """åé›†ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¨å¥¨"""

        recommendations = {
            'high_priority': [],
            'medium_priority': [],
            'experimental': [],
            'reasoning': {}
        }

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æã«åŸºã¥ãæ¨å¥¨
        existing_sexual_rate = model_analysis.get('sexual_expression_rate', 0)

        if existing_sexual_rate < 0.1:  # 10%æœªæº€
            recommendations['high_priority'].extend(self.japanese_erotic[:10])
            recommendations['high_priority'].extend(self.age_body_types[:5])
            recommendations['reasoning']['high_priority'] = "æ€§çš„è¡¨ç¾ãŒå°‘ãªã„ãŸã‚ã€åŸºæœ¬çš„ãªã‚¨ãƒ­ãƒ†ã‚£ãƒƒã‚¯è¡¨ç¾ã‚’å„ªå…ˆ"

        elif existing_sexual_rate < 0.3:  # 30%æœªæº€
            recommendations['medium_priority'].extend(self.bdsm_detailed[:8])
            recommendations['medium_priority'].extend(self.group_activities[:6])
            recommendations['reasoning']['medium_priority'] = "ä¸­ç¨‹åº¦ã®æ€§çš„è¡¨ç¾ãŒã‚ã‚‹ãŸã‚ã€ã‚ˆã‚Šå°‚é–€çš„ãªè¡¨ç¾ã‚’è¿½åŠ "

        else:  # 30%ä»¥ä¸Š
            recommendations['experimental'].extend(self.special_fetishes[:10])
            recommendations['experimental'].extend(self.pregnancy_lactation[:5])
            recommendations['reasoning']['experimental'] = "è±Šå¯Œãªæ€§çš„è¡¨ç¾ãŒã‚ã‚‹ãŸã‚ã€ç‰¹æ®Šãƒ•ã‚§ãƒã‚„å°‚é–€ã‚«ãƒ†ã‚´ãƒªã‚’å®Ÿé¨“"

        return recommendations

def add_keyword_target_ui():
    """Streamlit UIã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ©Ÿèƒ½è¿½åŠ """
    import streamlit as st

    st.markdown("### ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåé›†")

    collector = KeywordTargetCollector()

    # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
    categories = collector.get_comprehensive_keywords()
    selected_categories = st.multiselect(
        "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ†ã‚´ãƒª",
        list(categories.keys()),
        format_func=lambda x: {
            'japanese_erotic': 'ğŸ‡¯ğŸ‡µ æ—¥æœ¬ãƒ»ã‚¢ãƒ‹ãƒ¡ç³»ã‚¨ãƒ­ï¼ˆahegao, paizuriç­‰ï¼‰',
            'pregnancy_lactation': 'ğŸ¤± å¦Šå¨ ãƒ»æ¯ä¹³ç³»ï¼ˆpregnant, lactationç­‰ï¼‰',
            'age_body_types': 'ğŸ‘© å¹´é½¢ãƒ»ä½“å‹ï¼ˆmilf, petite, thiccç­‰ï¼‰',
            'lesbian_content': 'ğŸ‘­ ãƒ¬ã‚ºãƒ“ã‚¢ãƒ³ï¼ˆlesbian, tribbingç­‰ï¼‰',
            'group_activities': 'ğŸ‘¥ ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆorgy, gangbangç­‰ï¼‰',
            'bdsm_detailed': 'â›“ï¸ BDSMè©³ç´°ï¼ˆshibari, edgingç­‰ï¼‰',
            'special_fetishes': 'ğŸ¦¶ ç‰¹æ®Šãƒ•ã‚§ãƒï¼ˆfeet, glassesç­‰ï¼‰'
        }.get(x, x)
    )

    # é¸æŠã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤º
    if selected_categories:
        all_selected_keywords = []
        for category in selected_categories:
            all_selected_keywords.extend(categories[category])

        st.write(f"**é¸æŠã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: {len(all_selected_keywords)}å€‹")

        with st.expander("ğŸ“‹ é¸æŠã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä¸€è¦§"):
            for category in selected_categories:
                st.write(f"**{category}**: {', '.join(categories[category])}")

    # å®Ÿè¡Œè¨­å®š
    col1, col2 = st.columns(2)
    with col1:
        max_per_keyword = st.number_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚ãŸã‚Šæœ€å¤§ä»¶æ•°", 10, 100, 30)
        nsfw_level = st.selectbox("NSFWãƒ¬ãƒ™ãƒ«", ["X", "Mature", "Soft"], index=0)
    with col2:
        enable_analysis = st.checkbox("åé›†å¾Œåˆ†æ", True)
        save_results = st.checkbox("çµæœä¿å­˜", True)

    return {
        'collector': collector,
        'selected_categories': selected_categories,
        'max_per_keyword': max_per_keyword,
        'nsfw_level': nsfw_level,
        'enable_analysis': enable_analysis,
        'save_results': save_results
    }
