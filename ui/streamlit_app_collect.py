"""
CivitAI Prompt Collector - Streamlit Web UI (with collection tab)
ã‚³ãƒ”ãƒ¼å…ƒ: streamlit_app.py ã«åé›†ã‚¿ãƒ–ã‚’è¿½åŠ ã—ãŸæ´¾ç”Ÿç‰ˆ
"""

# UIåˆ¶å¾¡ãƒ•ãƒ©ã‚°ï¼ˆé–‹ç™ºæ™‚ã®ã¿ True ã«å¤‰æ›´ï¼‰
SHOW_LEGACY_UI_COMPONENTS = False  # æœ¬ç•ªã§ã¯ False

import streamlit as st
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
import pandas as pd
import requests
from src.database import DatabaseManager
try:
    import plotly.express as px  # type: ignore[import]
    PLOTLY_AVAILABLE = True
except ImportError:
    PLOTLY_AVAILABLE = False
try:
    import matplotlib.pyplot as plt  # type: ignore[import]
except ImportError:
    plt = None
import sqlite3
import uuid
from pathlib import Path
import sys
import subprocess
from datetime import datetime, timedelta, timezone
import re
import ast
import os
import time
import math

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¨DBãƒ‘ã‚¹å®šç¾©
project_root = Path(__file__).parent.parent
DEFAULT_DB_PATH = str(project_root / 'data' / 'civitai_dataset.db')
import sys
sys.path.append(str(project_root / 'src'))

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="CivitAI Prompt Collector (Collect)",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ  CSS
st.markdown("""
<style>
    .metric-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .category-badge {
        background-color: #e1f5fe;
        color: #01579b;
        padding: 0.2rem 0.5rem;
        border-radius: 15px;
        font-size: 0.8rem;
        margin: 0.1rem;
        display: inline-block;
    }
    .prompt-card {
        background-color: #ffffff;
        border-left: 4px solid #1f77b4;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    try:
        conn = sqlite3.connect(DEFAULT_DB_PATH)
        query = """
        SELECT
            id,
            civitai_id,
            full_prompt,
            negative_prompt,
            quality_score,
            reaction_count,
            comment_count,
            download_count,
            prompt_length,
            tag_count,
            model_name,
            model_id,
            collected_at,
            model_version_id
        FROM civitai_prompts
        WHERE full_prompt IS NOT NULL
        ORDER BY quality_score DESC
        """
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

@st.cache_data
def get_database_stats():
    try:
        db_manager = DatabaseManager()
        total_prompts = db_manager.get_prompt_count()
        query = """
        SELECT category, COUNT(*) as count, AVG(confidence) as avg_confidence
        FROM prompt_categories
        GROUP BY category
        ORDER BY count DESC
        """
        conn = db_manager._get_connection()
        category_stats = pd.read_sql_query(query, conn)
        conn.close()
        return {
            'total_prompts': total_prompts,
            'total_categorized': len(category_stats) > 0,
            'category_stats': category_stats
        }
    except Exception as e:
        st.error(f"çµ±è¨ˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return {'total_prompts': 0, 'total_categorized': False, 'category_stats': pd.DataFrame()}

def create_category_distribution_chart(df):
    if df.empty:
        return None

    # categoryã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if 'category' not in df.columns:
        return None

    category_counts = df['category'].value_counts()
    df_counts = category_counts.rename_axis('category').reset_index(name='count')
    colors = {
        'NSFW': '#ff6b6b',
        'style': '#4ecdc4',
        'lighting': '#ffe66d',
        'composition': '#a8e6cf',
        'mood': '#ff8b94',
        'basic': '#b4a7d6',
        'technical': '#d4a574'
    }
    if PLOTLY_AVAILABLE:
        fig = px.pie(data_frame=df_counts, names='category', values='count', title="ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ", color_discrete_map=colors, hover_data=['count'])
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.update_layout(font=dict(size=12), showlegend=True, height=500)
        return fig
    else:
        fig, ax = plt.subplots(figsize=(6, 6))
        wedges, texts, autotexts = ax.pie(df_counts['count'], labels=df_counts['category'], autopct='%1.1f%%', colors=[colors.get(c, None) for c in df_counts['category']])
        ax.set_title('ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ')
        plt.tight_layout()
        return fig

def create_confidence_histogram(df):
    if df.empty or 'confidence' not in df.columns:
        return None
    if PLOTLY_AVAILABLE:
        fig = px.histogram(df, x='confidence', nbins=20, title='åˆ†é¡ä¿¡é ¼åº¦ã®åˆ†å¸ƒ', labels={'confidence': 'ä¿¡é ¼åº¦', 'count': 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°'}, color_discrete_sequence=['#1f77b4'])
        fig.update_layout(xaxis_title="ä¿¡é ¼åº¦", yaxis_title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", font=dict(size=12), height=400)
        return fig

    else:
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.hist(df['confidence'].dropna(), bins=20, color='#1f77b4')
        ax.set_title('åˆ†é¡ä¿¡é ¼åº¦ã®åˆ†å¸ƒ')
        ax.set_xlabel('ä¿¡é ¼åº¦')
        ax.set_ylabel('ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°')
        plt.tight_layout()
        return fig


def display_chart(fig):
    """Display a figure produced by either plotly or matplotlib safely.
    If plotly is available and the figure looks like a plotly figure, use st.plotly_chart.
    Otherwise fall back to st.pyplot for matplotlib figures.
    """
    try:
        if PLOTLY_AVAILABLE:
            # plotly figures typically have 'to_plotly_json' or come from plotly.graph_objs
            # Use a conservative check to avoid importing plotly modules here.
            if hasattr(fig, 'to_plotly_json') or getattr(fig, '__module__', '').startswith('plotly'):
                st.plotly_chart(fig, config={'displayModeBar': False})
                return
        # Fallback: assume matplotlib figure
        try:
            import matplotlib.pyplot as _plt  # noqa: F401
        except Exception:
            pass
        st.pyplot(fig)
    except Exception:
        # Last-resort: just print the object
        st.write(fig)
    # end display_chart

def display_prompt_card(row):
    with st.container():
        # Noneã‚»ãƒ¼ãƒ•ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        prompt_id = row.get('id', 'N/A') or 'N/A'
        category = row.get('category', 'Unknown') or 'Unknown'
        confidence = row.get('confidence', 0.0) or 0.0
        model_name = row.get('model_name', 'Unknown') or 'Unknown'
        model_id = row.get('model_id', 'N/A') or 'N/A'
        collected_at = row.get('collected_at', '') or ''

        st.markdown(f"""
        <div class="prompt-card">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 0.5rem;">
                <strong>ID: {prompt_id}</strong>
                <span class="category-badge">{category} ({confidence:.2f})</span>
            </div>
            <div style="margin-bottom: 0.5rem;">
                <strong>ãƒ¢ãƒ‡ãƒ«:</strong> {model_name} (ID: {model_id})
            </div>
                <div style="margin-bottom: 0.5rem;">
                <strong>ä½œæˆæ—¥:</strong> {collected_at}
            </div>
        </div>
        """, unsafe_allow_html=True)

        prompt_id = row.get('id', '')
        show_key = f"show_prompt_{prompt_id}"
        placeholder = st.empty()

        def _show_prompt(id=prompt_id):
            st.session_state[f"show_prompt_{id}"] = True

        if st.session_state.get(show_key, False):
            full_key = f"full_prompt_{prompt_id}"
            neg_key = f"neg_prompt_{prompt_id}"
            with placeholder.container():
                st.text_area("ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", value=row.get('full_prompt', ''), height=100, disabled=True, key=full_key)
                if pd.notna(row.get('negative_prompt')) and str(row.get('negative_prompt')).strip():
                    st.text_area("ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", value=row.get('negative_prompt', ''), height=80, disabled=True, key=neg_key)
                if st.button("é–‰ã˜ã‚‹", key=f"close_{prompt_id}"):
                    st.session_state[show_key] = False
                    try:
                        if hasattr(st, 'experimental_rerun'):
                            st.experimental_rerun()
                        else:
                            import streamlit.components.v1 as components
                            components.html('<script>window.location.reload()</script>', height=0)
                    except Exception:
                        st.stop()
        else:
            if placeholder.button("è©³ç´°ã‚’è¡¨ç¤º", key=f"open_{prompt_id}", on_click=_show_prompt, args=()):
                try:
                    if hasattr(st, 'experimental_rerun'):
                        st.experimental_rerun()
                    else:
                        import streamlit.components.v1 as components
                        components.html('<script>window.location.reload()</script>', height=0)
                except Exception:
                    st.stop()

def read_log_tail(path, lines=50):
    from pathlib import Path
    log_path = Path(path)
    if not log_path.is_absolute():
        log_path = Path(__file__).parent.parent / log_path
    if not log_path.exists():
        return ''
    try:
        with log_path.open('r', encoding='utf-8', errors='replace') as f:
            data = f.read()
            return '\n'.join(data.splitlines()[-lines:])
    except Exception:
        return ''

def extract_progress_from_log(tail):
    if not tail:
        return None
    patterns = [
        r'Collected total=(\d+)',
        r'valid=(\d+)',
        r'åé›†æ¸ˆã¿[ï¼š:]\s*(\d+)',
        r'é€²æ—[ï¼š:]\s*(\d+)',
        r'saved=(\d+)',
        r'new_saved=(\d+)'
    ]
    for pattern in patterns:
        matches = re.findall(pattern, tail)
        if matches:
            try:
                return int(matches[-1])
            except:
                continue
    return None

def infer_status_from_tail(tail):
    # tailãŒç©ºã§ã‚‚ã€ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚Œã°'æº–å‚™ä¸­'ã‚„'å®Ÿè¡Œä¸­'ã¨åˆ¤å®š
    if tail is None:
        return 'æœªé–‹å§‹/å¾…æ©Ÿä¸­'
    if tail == '':
        return 'æº–å‚™ä¸­/å®Ÿè¡Œä¸­'
    low = tail.lower()
    if 'traceback' in low or 'error' in low:
        return 'å¤±æ•—'
    if '=== collection started' in low:
        if '=== collection finished' in low:
            return 'å®Œäº†'
        return 'åé›†ä¸­'
    if 'collected total' in low or 'collected=' in low or 'collected ' in low:
        return 'åé›†ä¸­'
    if '=== collection finished' in low or 'collection finished' in low:
        return 'å®Œäº†'
    if 'saved' in low and ('items' in low or 'item' in low):
        return 'å®Œäº†'
    if 'categorization finished' in low or 'categorisation finished' in low:
        return 'å®Œäº†'
    return 'å®Ÿè¡Œä¸­'

def parse_job_summary(tail: str) -> dict:
    """Parse known log markers from the job tail and return a summary dict."""
    summary = {
        'collected': None,
        'valid': None,
        'saved': None,
        'attempted': None,
        'new_saved': None,
        'duplicates': None,
        'sample_ids': [],
        'updated_count': 0,
        'api_total': None
    }
    if not tail:
        return summary
    for line in tail.splitlines():
        l = line.strip()
        # Collected total patterns
        m = re.search(r'Collected total=(\d+)', l)
        if m:
            try:
                summary['collected'] = int(m.group(1))
            except Exception:
                pass
        m = re.search(r'valid=(\d+)', l)
        if m:
            try:
                summary['valid'] = int(m.group(1))
            except Exception:
                pass

        # Saved explicit
        m = re.search(r'Saved\s+(\d+)\s+items to DB', l)
        if m:
            try:
                summary['saved'] = int(m.group(1))
            except Exception:
                pass

        # Batch result
        m = re.search(r'Batch result: attempted=(\d+)\s+new_saved=(\d+)\s+duplicates=(\d+)', l)
        if m:
            try:
                summary['attempted'] = int(m.group(1))
                summary['new_saved'] = int(m.group(2))
                summary['duplicates'] = int(m.group(3))
            except Exception:
                pass

        # Done line
        m = re.search(r'\[Done\] Collected unique prompts: .* saved=(\d+)', l)
        if m:
            try:
                summary['saved'] = int(m.group(1))
            except Exception:
                pass

        # Sample ids
        m = re.search(r"\[DB\] sample civitai_ids:\s*(\[.*\])", l)
        if m:
            try:
                # use ast.literal_eval to parse list-like Python repr
                vals = ast.literal_eval(m.group(1))
                if isinstance(vals, (list, tuple)):
                    summary['sample_ids'] = [str(x) for x in vals]
            except Exception:
                pass

        # Updated existing lines
        if '[DB] Updated existing civitai_id=' in l or 'Updated existing civitai_id=' in l:
            summary['updated_count'] += 1

        # API preview marker (from collect_from_ui logs)
        m = re.search(r'API preview: totalItems reported -> (\d+)', l)
        if m:
            try:
                summary['api_total'] = int(m.group(1))
            except Exception:
                pass

    return summary

@st.cache_data(ttl=2)
def load_data_no_cache():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã‚ãªã„ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
    try:
        db_manager = DatabaseManager()
        query = """
        SELECT
            p.id,
            p.full_prompt,
            p.negative_prompt,
            p.model_name,
            p.model_id,
            p.collected_at,
            pc.category,
            pc.confidence
        FROM civitai_prompts p
        LEFT JOIN prompt_categories pc ON p.id = pc.prompt_id
        ORDER BY p.collected_at DESC
        """
        conn = db_manager._get_connection()
        df = pd.read_sql_query(query, conn)
        conn.close()
        return df
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

def main():
    global sys
    import sys
    global Path
    from pathlib import Path
    project_root = Path(__file__).parent.parent
    from pathlib import Path
    # åé›†ã‚¸ãƒ§ãƒ–çŠ¶æ…‹ã®è‡ªå‹•æ›´æ–°ï¼ˆ3ç§’ã”ã¨ï¼‰
    st_autorefresh = getattr(st, 'autorefresh', None)
    # intervalã‚’1000msï¼ˆ1ç§’ï¼‰ã«çŸ­ç¸®ã—ã€ç¢ºå®Ÿã«è‡ªå‹•æ›´æ–°
    if st_autorefresh:
        st_autorefresh(interval=1000, key="job_status_autorefresh")
    st.title("ğŸ¨ CivitAI Prompt Collector - Collect")
    st.markdown("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†æãƒ»è¡¨ç¤ºãƒ»åé›†ã‚¿ãƒ–ã‚’æä¾›ã—ã¾ã™")

    df = load_data()
    stats = get_database_stats()

    st.sidebar.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ")
    if st.sidebar.button("ğŸ”„ ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼‰"):
        try:
            st.cache_data.clear()
        except Exception:
            try:
                st.experimental_memo_clear()
            except Exception:
                pass
        try:
            if hasattr(st, 'experimental_rerun'):
                st.experimental_rerun()
            else:
                raise AttributeError('experimental_rerun not available')
        except Exception:
            try:
                import streamlit.components.v1 as components
                components.html('<script>window.location.reload()</script>', height=0)
            except Exception:
                st.stop()

    st.sidebar.metric("ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", stats['total_prompts'])

    # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ©ãƒ å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if 'category' in df.columns:
        st.sidebar.metric("åˆ†é¡æ¸ˆã¿æ•°", len(df[df['category'].notna()]))
    else:
        st.sidebar.metric("åˆ†é¡æ¸ˆã¿æ•°", "ã‚«ãƒ†ã‚´ãƒªæœªå®Ÿè£…")

    tab_collect, tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” åé›†", "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§", "ğŸ“ˆ è©³ç´°åˆ†æ", "ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"])

    with tab_collect:
        st.header("ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆCivitAI APIï¼‰")
        st.markdown("ãƒ¢ãƒ‡ãƒ«IDã¾ãŸã¯ãƒãƒ¼ã‚¸ãƒ§ãƒ³IDã‚’æŒ‡å®šã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åé›†ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ã€‚å®Œäº†å¾Œã«è‡ªå‹•ã§å†åˆ†é¡ã‚’è¡Œã„ã€UIã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™ã€‚")

        col_a, col_b = st.columns(2)
        with col_a:
            model_id = st.text_input("Model IDï¼ˆãƒ¢ãƒ‡ãƒ«è­˜åˆ¥å­ã€ä»»æ„ï¼‰", value="", key='model_id_input', help="ãƒ¢ãƒ‡ãƒ«ã® IDã€‚é€šå¸¸ã¯æ•°å€¤ã® modelIdï¼ˆä¾‹: 101055ï¼‰ã‚„æ–‡å­—åˆ—ãŒå…¥ã‚Šã¾ã™ã€‚")
            # Provide a button to fetch model metadata (name + versions) from CivitAI
            fetch_info = st.button("ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—", key='fetch_model_info')

            # If user clicked 'fetch_info', call API to populate model_name and versions
            if fetch_info and model_id:
                try:
                    import sys
                    from pathlib import Path
                    project_root = Path(__file__).parent.parent
                    sys.path.append(str(project_root / 'src'))
                    import config
                    API_BASE_URL = config.API_BASE_URL
                    REQUEST_TIMEOUT = config.REQUEST_TIMEOUT
                    USER_AGENT = config.USER_AGENT
                    CIVITAI_API_KEY = config.CIVITAI_API_KEY
                    base_api = API_BASE_URL.rsplit('/', 1)[0]
                    model_url = f"{base_api}/models/{str(model_id).strip()}"
                    headers = {"User-Agent": USER_AGENT}
                    if CIVITAI_API_KEY:
                        headers['Authorization'] = f"Bearer {CIVITAI_API_KEY}"
                    resp = requests.get(model_url, headers=headers, timeout=REQUEST_TIMEOUT)
                    if resp.status_code == 200:
                        j = resp.json()
                        mname = j.get('name') or j.get('title') or j.get('modelName')
                        if mname:
                            st.session_state['model_name_input'] = mname
                        # build versions list
                        mvers = j.get('modelVersions') or j.get('versions') or []
                        vers = []
                        for v in mvers:
                            if isinstance(v, dict):
                                vid = v.get('id') or v.get('modelVersionId')
                                vname = v.get('name') or ''
                                if vid:
                                    vers.append({'id': str(vid), 'name': vname})
                        if vers:
                            st.session_state['model_versions'] = vers
                            # preselect first
                            st.session_state['version_select'] = 0
                    else:
                        st.warning(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: HTTP {resp.status_code}")
                except Exception as e:
                    st.error(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                    # fallback to DB lookup
                    try:
                        db_path = DEFAULT_DB_PATH
                        conn = sqlite3.connect(db_path)
                        cur = conn.cursor()
                        cur.execute("SELECT model_name FROM civitai_prompts WHERE model_id = ? AND model_name IS NOT NULL AND model_name <> '' LIMIT 1", (str(model_id).strip(),))
                        row = cur.fetchone()
                        if row and row[0]:
                            st.session_state['model_name_input'] = row[0]
                        conn.close()
                    except Exception:
                        pass

            # Version input: if we have discovered versions, show a selectbox, otherwise fallback to text input
            versions = st.session_state.get('model_versions', None)
            if versions:
                # versions is list of dicts with keys 'id' and 'name'
                opts = [f"{v.get('id')} - {v.get('name', '')}" for v in versions]
                # Normalize stored index/value to a serializable string if needed
                try:
                    existing = st.session_state.get('version_select', None)
                    if isinstance(existing, int):
                        # keep as index (old behavior) by ensuring index is in range
                        if existing < 0 or existing >= len(opts):
                            st.session_state['version_select'] = 0
                    elif existing is not None and existing not in opts:
                        # remove invalid stored value to avoid serialization issues
                        try:
                            del st.session_state['version_select']
                        except Exception:
                            st.session_state['version_select'] = 0
                except Exception:
                    st.session_state['version_select'] = 0

                # Ensure we always pass strings to selectbox; use index-based default when possible
                default_index = 0
                try:
                    if isinstance(st.session_state.get('version_select', None), int):
                        default_index = st.session_state.get('version_select')
                except Exception:
                    default_index = 0

                # Use selectbox without a persistent key to avoid session_state type conflicts
                sel = st.selectbox("Versionï¼ˆé¸æŠï¼‰", options=opts, index=default_index)
                # extract id from selected option string like '123 - name'
                if isinstance(sel, str):
                    version_id = str(sel.split(' - ', 1)[0])
                else:
                    version_id = str(sel)
            else:
                version_id = st.text_input("Version IDï¼ˆæ•°å€¤ã€å¿…é ˆï¼‰", value="", key='version_id_input', help="ãƒãƒ¼ã‚¸ãƒ§ãƒ³IDï¼ˆæ•°å€¤ï¼‰ã‚’å¿…ãšæŒ‡å®šã—ã¦ãã ã•ã„ã€‚æŒ‡å®šã™ã‚‹ã¨ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åé›†ã—ã¾ã™ã€‚")

            # model_name input uses a session_state key so we can autofill it
            model_name = st.text_input("ãƒ¢ãƒ‡ãƒ«åï¼ˆè‡ªå‹•è£œå®Œï¼‰", value=st.session_state.get('model_name_input', ''), key='model_name_input')
            # Default to a conservative limit (1000) to avoid accidental large runs
            max_items = st.number_input("æœ€å¤§å–å¾—ä»¶æ•°", value=1000, min_value=1, max_value=100000, step=1)
            status_check = st.button("çŠ¶æ³ã‚’ç¢ºèªï¼ˆDBä»¶æ•° + APIä»¶æ•°å–å¾—ï¼‰", key='status_check')
        with col_b:
            st.write("å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³")
            run_save = st.checkbox("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹", value=True)
            run_categorize = st.checkbox("åé›†å¾Œã«è‡ªå‹•ã§å†åˆ†é¡ã™ã‚‹", value=True)
            strict_version_match = st.checkbox("å³å¯†ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸€è‡´ã®ã¿è¨±å¯ (checkpoint ã®ã¿)", value=False, help="æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€meta.civitaiResources ã® checkpoint ãƒªã‚½ãƒ¼ã‚¹ã¨æ­£ç¢ºã«ä¸€è‡´ã™ã‚‹å ´åˆã®ã¿ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚")

        # Status check: show DB counts and API totalItems when requested
        if status_check:
            try:
                db = DatabaseManager()
                # Count records that reference this version in model_version_id OR raw_metadata
                vcount = 0
                rawcount = 0
                if version_id and str(version_id).strip():
                    conn = db._get_connection()
                    cur = conn.cursor()
                    try:
                        cur.execute('SELECT COUNT(*) FROM civitai_prompts WHERE model_version_id = ?', (str(version_id).strip(),))
                        vcount = cur.fetchone()[0]
                        # also count raw_metadata contains as a hint
                        cur.execute('SELECT COUNT(*) FROM civitai_prompts WHERE raw_metadata LIKE ?', (f"%{str(version_id).strip()}%",))
                        rawcount = cur.fetchone()[0]
                    finally:
                        conn.close()
                    st.info(f"DB: model_version_id == {version_id} ã®ä»¶æ•°: {vcount} (raw_metadata ã« {rawcount} ä»¶å«ã‚€)")
                else:
                    st.info("Version ID ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

                # check API totalItems via collector helper
                try:
                    from src.collector import check_total_items
                    total = check_total_items(model_id=model_id if model_id else None, version_id=version_id if version_id else None)
                    if total is not None:
                        st.success(f"API ãŒå ±å‘Šã™ã‚‹ç·ä»¶æ•°: {total} ä»¶")
                    else:
                        st.warning("API ã¯ totalItems ã‚’è¿”ã—ã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚«ãƒ¼ã‚½ãƒ«æ–¹å¼ã§åé›†ã•ã‚Œã¾ã™ï¼‰")
                except Exception as e:
                    st.error(f"API ä»¶æ•°ç¢ºèªã«å¤±æ•—: {e}")
            except Exception as e:
                st.error(f"çŠ¶æ³ç¢ºèªã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # Immediate preview: always show DB counts + API total (helps explain 0/å°‘æ•°ã®åŸå› )
        try:
            if version_id and str(version_id).strip():
                db = DatabaseManager()
                conn = db._get_connection()
                cur = conn.cursor()
                try:
                    cur.execute('SELECT COUNT(*) FROM civitai_prompts WHERE model_version_id = ?', (str(version_id).strip(),))
                    vcount = cur.fetchone()[0]
                    cur.execute('SELECT COUNT(*) FROM civitai_prompts WHERE raw_metadata LIKE ?', (f"%{str(version_id).strip()}%",))
                    rawcount = cur.fetchone()[0]
                finally:
                    conn.close()

                # API preview
                try:
                    from src.collector import check_total_items
                    total = check_total_items(model_id=model_id if model_id else None, version_id=version_id if version_id else None)
                except Exception:
                    total = None

                col1, col2, col3 = st.columns(3)
                col1.metric(f"DB ä¿å­˜æ¸ˆã¿ (model_version_id == {version_id})", vcount)
                col2.metric("raw_metadata ã«å‡ºç¾", rawcount)
                if total is not None:
                    col3.metric("API ãŒå ±å‘Šã™ã‚‹ç·ä»¶æ•°", total)
                else:
                    col3.metric("API ãŒå ±å‘Šã™ã‚‹ç·ä»¶æ•°", "N/A")

                if SHOW_LEGACY_UI_COMPONENTS:
                    with st.expander("è£œè¶³: ãªãœ0ä»¶/å°‘æ•°ã‹ã‚’åˆ¤æ–­ã™ã‚‹ãŸã‚ã®ãƒ’ãƒ³ãƒˆ"):
                        st.markdown("""
                        - DB å´ã® `model_version_id` ãŒæœªè¨­å®šï¼ˆä»Šå›ã®è£œå®Œã§åŸ‹ã‚ã‚‰ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã ã¨ UI ã«ä¿å­˜æ•°ãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚
                        - raw_metadata ã«è©²å½“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ä»¶æ•°ã¯ãƒ’ãƒ³ãƒˆã«ãªã‚Šã¾ã™ï¼ˆå¿…ãšã—ã‚‚ä¿å­˜å¯¾è±¡ã¨ã¯é™ã‚Šã¾ã›ã‚“ï¼‰ã€‚
                        - API ã® totalItems ã¯åˆ©ç”¨å¯èƒ½ãªå ´åˆã«ã®ã¿è¿”ã•ã‚Œã¾ã™ï¼ˆè¿”ã•ãªã„APIã¯ã‚«ãƒ¼ã‚½ãƒ«æ–¹å¼ã§å…¨ä»¶å–å¾—ã•ã‚Œã¾ã™ï¼‰ã€‚
                        """)
            else:
                st.info("Version ID ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€DB ã«ä¿å­˜æ¸ˆã¿ã®ä»¶æ•°ã¨ API ã®ç·ä»¶æ•°ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¾ã™ã€‚")
        except Exception as e:
            st.warning(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # Require version_id to run
        version_required = True
        start_disabled = False
        if version_required and (not (version_id and str(version_id).strip())):
            start_disabled = True
            st.warning("Version ID ã¯å¿…é ˆã§ã™ã€‚Version ID ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        if SHOW_LEGACY_UI_COMPONENTS:
            start_button = st.button("â–¶ åé›†é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰", disabled=start_disabled)
            # New controls: Full Collect, Resume, Stop
            st.write('')
        else:
            start_button = False

        if SHOW_LEGACY_UI_COMPONENTS and st.button('ğŸ” å…¨ä»¶åé›†ï¼ˆæœ€åˆã‹ã‚‰æœ€å¾Œã¾ã§ï¼‰', disabled=start_disabled):
            # Start full collect (no max-items limit) as background job
            job_id = str(uuid.uuid4())[:8]
            log_dir = Path(project_root) / 'scripts'
            log_file = log_dir / f'collect_full_{job_id}.log'
            def _clean_id_local(s):
                if not s:
                    return ''
                return str(s).strip().rstrip('/')

            args = [
                sys.executable,
                str(Path(project_root) / 'scripts' / 'collect_from_ui.py'),
                '--model-id', _clean_id_local(model_id) or '',
                '--version-id', _clean_id_local(version_id) or '',
                '--model-name', (model_name or ''),
                '--max-items', str(0),
                '--save' if run_save else '--no-save',
                '--categorize' if run_categorize else '--no-categorize',
                '--log-file', str(log_file)
            ]
            if strict_version_match:
                args.append('--strict-version-match')
            try:
                subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=str(project_root))
                # record requested_max_items for clearer job summaries (0 means unlimited)
                job = {'id': job_id, 'log_file': str(log_file), 'model_id': _clean_id_local(model_id), 'version_id': (_clean_id_local(version_id) or ''), 'model_name': model_name, 'started_at': datetime.utcnow().isoformat() + 'Z', 'status': 'running', 'last_tail': '', 'requested_max_items': 0}
                st.session_state.setdefault('collect_jobs', []).insert(0, job)
                st.success(f"ãƒ•ãƒ«åé›†ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {job_id}")
            except Exception as e:
                st.error(f"ã‚¸ãƒ§ãƒ–é–‹å§‹å¤±æ•—: {e}")

        if SHOW_LEGACY_UI_COMPONENTS and st.button('â–¶ å†é–‹ï¼ˆä¿å­˜ã•ã‚ŒãŸçŠ¶æ…‹ã‹ã‚‰ï¼‰'):
            # Start resume job using scripts/resume_collect.py
            job_id = str(uuid.uuid4())[:8]
            log_dir = Path(project_root) / 'scripts'
            log_file = log_dir / f'collect_resume_{job_id}.log'
            def _clean_id_local(s):
                if not s:
                    return ''
                return str(s).strip().rstrip('/')
            args = [
                sys.executable,
                str(Path(project_root) / 'scripts' / 'resume_collect.py'),
                '--log-file', str(log_file)
            ]
            try:
                subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=str(project_root))
                job = {'id': job_id, 'log_file': str(log_file), 'model_id': _clean_id_local(model_id), 'version_id': (_clean_id_local(version_id) or ''), 'model_name': model_name, 'started_at': datetime.utcnow().isoformat() + 'Z', 'status': 'running', 'last_tail': ''}
                st.session_state.setdefault('collect_jobs', []).insert(0, job)
                st.success(f"å†é–‹ã‚¸ãƒ§ãƒ–ã‚’é–‹å§‹ã—ã¾ã—ãŸ: {job_id}")
            except Exception as e:
                st.error(f"å†é–‹ã‚¸ãƒ§ãƒ–é–‹å§‹å¤±æ•—: {e}")

        # åœæ­¢ãƒœã‚¿ãƒ³ã¯é‡è¦ãªã®ã§å¸¸ã«è¡¨ç¤º
        if st.button('â¹ åœæ­¢ï¼ˆå®Ÿè¡Œä¸­ã‚¸ãƒ§ãƒ–ã¸åœæ­¢æŒ‡ç¤ºï¼‰'):
            # Create stop file used by collector scripts to gracefully stop
            stop_file = Path(project_root) / 'scripts' / 'collect_stop.flag'
            try:
                stop_file.write_text('stop')
                st.info('åœæ­¢ãƒ•ãƒ©ã‚°ã‚’ä½œæˆã—ã¾ã—ãŸã€‚å®Ÿè¡Œä¸­ã®ã‚¸ãƒ§ãƒ–ã¯æ¬¡ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§åœæ­¢ã—ã¾ã™ã€‚')
            except Exception as e:
                st.error(f'åœæ­¢ãƒ•ãƒ©ã‚°ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}')

        if start_button:
            # Launch background subprocess to run collection
            job_id = str(uuid.uuid4())[:8]
            # write this job's log to the centralized logs/collect_jobs directory
            log_dir = Path(project_root) / 'logs' / 'collect_jobs'
            log_file = log_dir / f'collect_job_{job_id}.log'

            # Enforce version_id usage: version is required and will be used as modelVersionId
            # Sanitize inputs: trim and remove trailing slashes
            def _clean_id(s):
                if not s:
                    return ''
                return str(s).strip().rstrip('/')

            selected_id = _clean_id(version_id) if version_id and str(version_id).strip() else (_clean_id(model_id) if model_id else None)

            args = [
                sys.executable,
                str(Path(project_root) / 'scripts' / 'collect_from_ui.py'),
                '--model-id', selected_id or '',
                '--version-id', _clean_id(version_id) or '',
                '--model-name', (model_name or ''),
                '--max-items', str(int(max_items)),
                '--no-save' if not run_save else '--save',
                '--categorize' if run_categorize else '--no-categorize',
                '--log-file', str(log_file)
            ]
            if strict_version_match:
                args.append('--strict-version-match')

            try:
                # Start subprocess detached
                subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, cwd=str(project_root))
                # register job in session_state
                job = {
                    'id': job_id,
                    'log_file': str(log_file),
                    'model_id': selected_id,
                    'version_id': (version_id or ''),
                    'model_name': (model_name or ''),
                    'started_at': datetime.utcnow().isoformat() + 'Z',
                    'status': 'running',
                    'last_tail': '',
                    'requested_max_items': int(max_items)
                }
                if 'collect_jobs' not in st.session_state:
                    st.session_state['collect_jobs'] = []
                st.session_state['collect_jobs'].insert(0, job)

                st.success(f"ã‚¸ãƒ§ãƒ–é–‹å§‹: {job_id} â€” ãƒ­ã‚°: {log_file}")
                st.write("ãƒ­ã‚°ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¦‹ã‚‹ã«ã¯åˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§æ¬¡ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
                st.code(f"Get-Content {log_file} -Wait -Tail 200", language='powershell')
            except Exception as e:
                st.error(f"ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¸ãƒ§ãƒ–ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

        # --- Job status display ---
        if SHOW_LEGACY_UI_COMPONENTS:
            st.subheader("åé›†ã‚¸ãƒ§ãƒ–ã®çŠ¶æ…‹")

        jobs = st.session_state.get('collect_jobs', [])
        db_manager = DatabaseManager()

        if SHOW_LEGACY_UI_COMPONENTS and jobs:
            for j in list(jobs):
                with st.expander(f"ã‚¸ãƒ§ãƒ– {j['id']} â€” ãƒ¢ãƒ‡ãƒ« {j.get('model_id','')} / ãƒãƒ¼ã‚¸ãƒ§ãƒ³ {j.get('version_id','')}"):
                    lf = str(Path(j.get('log_file')).as_posix())
                    tail = read_log_tail(lf, lines=80)
                    version_id_str = str(j.get('version_id')) if j.get('version_id') is not None else ''
                    cs_list = db_manager.get_collection_state_for_version(version_id_str)
                    cs = cs_list[0] if cs_list else None
                    # å®Œäº†åˆ¤å®š: ãƒ­ã‚°tailã¾ãŸã¯DBé€²æ—ã«å®Œäº†ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚Œã°å¿…ãš'å®Œäº†'
                    status = None
                    tail_lower = tail.lower() if tail else ''
                    is_finished = False
                    if cs and 'status' in cs and cs['status'] in ('completed', 'å®Œäº†'):
                        is_finished = True
                    if '=== collection finished' in tail_lower or 'job summary' in tail_lower:
                        is_finished = True
                    if is_finished:
                        status = 'å®Œäº†'
                    else:
                        if cs and 'status' in cs:
                            status = cs['status']
                        else:
                            status = infer_status_from_tail(tail)
                    # é€²æ—ãƒ»äºˆå®šä»¶æ•°
                    total_collected = cs['total_collected'] if cs and 'total_collected' in cs else None
                    planned_total = cs['planned_total'] if cs and 'planned_total' in cs else j.get('requested_max_items', None)
                    last_update = cs['last_update'] if cs and 'last_update' in cs else None
                    started_at = j.get('started_at')
                    def to_jst(dtstr):
                        try:
                            dt = datetime.fromisoformat(str(dtstr).replace('Z',''))
                            jst = dt.astimezone(timezone(timedelta(hours=9)))
                            return jst.strftime('%Y-%m-%d %H:%M:%S JST')
                        except Exception:
                            return str(dtstr)
                    elapsed_sec = None
                    if started_at and last_update:
                        try:
                            dt_start = datetime.fromisoformat(str(started_at).replace('Z',''))
                            dt_last = datetime.fromisoformat(str(last_update).replace('Z',''))
                            elapsed_sec = (dt_last - dt_start).total_seconds()
                        except Exception:
                            elapsed_sec = None
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»é€²æ—ãƒãƒ¼ï¼ˆä¸Šéƒ¨ï¼‰
                    st.markdown("### ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
                    cols_status = st.columns([2,2,2,2])
                    with cols_status[0]:
                        if status in ('running', 'åé›†ä¸­'):
                            st.info('çŠ¶æ…‹: å®Ÿè¡Œä¸­')
                        elif status in ('completed', 'å®Œäº†'):
                            st.success('çŠ¶æ…‹: å®Œäº†')
                        elif status in ('failed', 'å¤±æ•—'):
                            st.error('çŠ¶æ…‹: å¤±æ•—')
                        elif status in ('idle', 'æœªé–‹å§‹/å¾…æ©Ÿä¸­', None):
                            st.write('çŠ¶æ…‹: æœªé–‹å§‹/å¾…æ©Ÿä¸­')
                        else:
                            st.write(f'çŠ¶æ…‹: {status}')
                    with cols_status[1]:
                        # é€²æ—ãƒãƒ¼ã¯å¸¸ã«è¡¨ç¤ºã€‚äºˆå®šä»¶æ•°ãŒä¸æ˜/ç„¡åˆ¶é™ãªã‚‰ä»®ã®æœ€å¤§å€¤ï¼ˆ1000ï¼‰ã§å‰²åˆè¨ˆç®—
                        bar_max = 1000
                        if planned_total and planned_total not in (None, 0, '0', 'unlimited'):
                            try:
                                bar_max = int(planned_total)
                            except Exception:
                                bar_max = 1000
                        bar_val = int(total_collected) if total_collected is not None else 0
                        # å®Œäº†æ™‚ã¯100%è¡¨ç¤º
                        if status in ('completed', 'å®Œäº†'):
                            progress = 1.0
                        else:
                            progress = min(1.0, bar_val / bar_max) if bar_max > 0 else 0.0
                        st.progress(progress, text=f"é€²æ—: {bar_val} / {bar_max} ä»¶ ({progress*100:.1f}%)")
                        if planned_total in (None, 0, '0', 'unlimited'):
                            st.write(f"é€²æ—: {bar_val} ä»¶ï¼ˆäºˆå®šä»¶æ•°ä¸æ˜/ç„¡åˆ¶é™ï¼‰")
                    with cols_status[2]:
                        if elapsed_sec is not None:
                            mins = int(elapsed_sec // 60)
                            secs = int(elapsed_sec % 60)
                            st.write(f"çµŒéæ™‚é–“: {mins}åˆ†{secs}ç§’")
                    with cols_status[3]:
                        st.write(f"é–‹å§‹: {to_jst(started_at)}")
                        if last_update:
                            st.write(f"æœ€çµ‚æ›´æ–°: {to_jst(last_update)}")
                    # ãƒ­ã‚°ãƒ»ã‚µãƒãƒªãƒ¼ï¼ˆä¸‹éƒ¨ï¼‰
                    st.markdown("### ãƒ­ã‚°ï¼ˆæœ«å°¾ï¼‰")
                    if tail:
                        st.code(tail, language='text')
                    else:
                        st.info('ãƒ­ã‚°ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚')
                    try:
                        summary = parse_job_summary(tail)
                        if any(v is not None for k,v in summary.items() if k in ('collected','saved','duplicates','new_saved')) or summary['sample_ids'] or summary['updated_count']:
                            st.markdown('### ã‚¸ãƒ§ãƒ–ã‚µãƒãƒªãƒ¼')
                            planned_display = planned_total if planned_total not in (None, 0, '0', '', 'None') else (j.get('requested_max_items') if j.get('requested_max_items', None) not in (None, 0, '0', '', 'None') else 'unlimited')
                            fetched = summary.get('collected') or summary.get('attempted') or summary.get('total_unique') or total_collected or 'N/A'
                            duplicates = summary.get('duplicates')
                            if duplicates is None and summary.get('attempted') is not None and summary.get('new_saved') is not None:
                                try:
                                    duplicates = int(summary.get('attempted')) - int(summary.get('new_saved'))
                                except Exception:
                                    duplicates = None
                            # ä¿å­˜ã•ã‚ŒãŸç·ä»¶æ•°ã‚’è¨ˆç®—ï¼ˆæ–°è¦ä¿å­˜ + æ›´æ–°ä»¶æ•°ï¼‰
                            new_saved = summary.get('new_saved') if summary.get('new_saved') is not None else (summary.get('saved') if summary.get('saved') is not None else 0)
                            updated_count = summary.get('updated_count') or 0
                            total_saved = (new_saved or 0) + updated_count

                            # ãƒ¡ã‚¤ãƒ³è¡¨ç¤º: æœ€ã‚‚é‡è¦ãªæƒ…å ±ã‚’å¼·èª¿
                            st.markdown("#### ğŸ“Š åé›†çµæœã‚µãƒãƒªãƒ¼")
                            cols_main = st.columns(3)
                            cols_main[0].metric('ğŸ¯ **ä»Šå›ä¿å­˜æˆåŠŸä»¶æ•°**', f"{total_saved}ä»¶", help="ã“ã®å®Ÿè¡Œã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ–°è¦ä¿å­˜/æ›´æ–°ã•ã‚ŒãŸä»¶æ•°")
                            cols_main[1].metric('ğŸ“¥ API ã‹ã‚‰å–å¾—', f"{fetched}ä»¶" if fetched != 'N/A' else 'N/A', help="CivitAI APIã‹ã‚‰å®Ÿéš›ã«å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ä»¶æ•°")
                            cols_main[2].metric('ğŸ“‹ å–å¾—äºˆå®š', planned_display, help="å½“åˆäºˆå®šã—ã¦ã„ãŸåé›†ä»¶æ•°")

                            # è©³ç´°æƒ…å ±
                            with st.expander("ğŸ“‹ è©³ç´°å†…è¨³", expanded=False):
                                cols_detail = st.columns(4)
                                cols_detail[0].metric('ğŸ†• æ–°è¦ä¿å­˜', new_saved or 0)
                                cols_detail[1].metric('ğŸ”„ æ—¢å­˜æ›´æ–°', updated_count)
                                cols_detail[2].metric('ğŸ” é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—', duplicates if duplicates is not None else 'N/A')
                                if summary.get('api_total') is not None:
                                    cols_detail[3].metric('ğŸ“Š APIç·ä»¶æ•°', summary.get('api_total'))

                            # å–å¾—ã¨ä¿å­˜ã®é–¢ä¿‚ã‚’èª¬æ˜
                            if fetched != 'N/A' and total_saved > 0:
                                fetch_count = int(fetched) if str(fetched).isdigit() else 0
                                if fetch_count > total_saved:
                                    st.info(f"ğŸ’¡ **èª¬æ˜**: APIã‹ã‚‰{fetch_count}ä»¶å–å¾—ã—ã¾ã—ãŸãŒã€{fetch_count - total_saved}ä»¶ã¯æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã—ã¦ã„ãŸãŸã‚é‡è¤‡ã¨ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
                                elif total_saved > 0:
                                    st.success(f"âœ… **çµæœ**: {total_saved}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")

                            if summary.get('sample_ids'):
                                st.write('ğŸ“ ã‚µãƒ³ãƒ—ãƒ« civitai_id: ' + ', '.join(summary.get('sample_ids')))
                    except Exception:
                        pass
                    col_refresh, col_open, col_remove = st.columns([1,2,1])
                    with col_refresh:
                        if st.button('æ›´æ–°', key=f'refresh_{j["id"]}'):
                            try:
                                st.session_state['__refresh_ts'] = time.time()
                                if hasattr(st, 'experimental_rerun'):
                                    st.experimental_rerun()
                            except Exception:
                                pass
                    with col_open:
                        if st.button('ãƒ­ã‚°ã‚’åˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§é–‹ã', key=f'open_{j["id"]}'):
                            st.write(f"PowerShell ã‚³ãƒãƒ³ãƒ‰: Get-Content {j.get('log_file')} -Wait -Tail 200")
                    with col_remove:
                        if st.button('ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤', key=f'remove_{j["id"]}'):
                            try:
                                st.session_state['collect_jobs'] = [x for x in st.session_state['collect_jobs'] if x['id'] != j['id']]
                                if hasattr(st, 'experimental_rerun'):
                                    st.experimental_rerun()
                            except Exception:
                                pass
        elif SHOW_LEGACY_UI_COMPONENTS:
            st.info('åé›†ä¸­ã®ã‚¸ãƒ§ãƒ–ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚')

        # Enhanced NSFW Collection Strategy
        st.markdown("---")
        st.markdown("### ğŸ”¥ åŠ¹ç‡çš„åé›†æˆ¦ç•¥")
        st.markdown("CivitAI APIåˆ¶ç´„ã‚’ç†è§£ã—ãŸåŠ¹ç‡çš„ãªåé›†æ–¹æ³•")

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèª
        try:
            db_manager = DatabaseManager()
            conn = db_manager._get_connection()
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM civitai_prompts')
            total_records = cursor.fetchone()[0]
            conn.close()

            # æ¨å¥¨æˆ¦ç•¥ã®è¡¨ç¤º
            if total_records == 0:
                st.warning(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ç©ºã§ã™ï¼ˆ{total_records}ä»¶ï¼‰ã€‚**åˆå›å…¨ä»¶åé›†** ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
                recommended_mode = "initial_full_collection"
            else:
                st.info(f"ğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿: {total_records:,}ä»¶ã€‚**ç¶™ç¶šè¿½åŠ åé›†** ã§åŠ¹ç‡çš„ã«æ›´æ–°ã§ãã¾ã™ã€‚")
                recommended_mode = "incremental_newest"
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
            recommended_mode = "comprehensive_multi"

        # åŒ…æ‹¬çš„åé›†æ©Ÿèƒ½ã®çµ±åˆ
        try:
            # Enhanced collection UI with efficient strategies
            available_modes = ["initial_full_collection", "incremental_newest", "comprehensive_multi", "nsfw_explicit_only", "standard_safe"]
            try:
                default_index = available_modes.index(recommended_mode)
            except:
                default_index = 0

            collection_mode = st.selectbox(
                "åé›†ãƒ¢ãƒ¼ãƒ‰",
                available_modes,
                index=default_index,
                format_func=lambda x: {
                    "initial_full_collection": "ğŸš€ æŒ‡å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³å…¨ä»¶åé›† - å…¨æˆ¦ç•¥å®Ÿè¡Œã§å½“è©²ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å…¨ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰",
                    "incremental_newest": "âš¡ ç¶™ç¶šè¿½åŠ åé›† - Newest ã®ã¿ã§åŠ¹ç‡çš„æ›´æ–°",
                    "comprehensive_multi": "ğŸ¯ åŒ…æ‹¬çš„ãƒãƒ«ãƒåé›†ï¼ˆå¾“æ¥ï¼‰- NSFW + å®‰å…¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
                    "nsfw_explicit_only": "ğŸ” NSFWæ˜ç¤ºçš„ã®ã¿ - æœ€å¤§é™ã®æ€§çš„è¡¨ç¾",
                    "standard_safe": "âœ… æ¨™æº–å®‰å…¨ãƒ¢ãƒ¼ãƒ‰ - å¾“æ¥ã®åé›†æ–¹æ³•"
                }[x],
                help="åŠ¹ç‡çš„ãªåé›†æˆ¦ç•¥: åˆå›ã¯å…¨ä»¶â†’ä»¥é™ã¯ Newest ã®ã¿æ¨å¥¨"
            )

            # æˆ¦ç•¥èª¬æ˜ã®è¡¨ç¤º
            if collection_mode == "initial_full_collection":
                st.info("ğŸ’¡ **æŒ‡å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³å…¨ä»¶åé›†**: æŒ‡å®šãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å…¨æˆ¦ç•¥ï¼ˆNSFW Ã— Sortï¼‰ã‚’å®Ÿè¡Œã—ã€ãã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰ã€‚é‡è¤‡ã¯é™¤å»ã•ã‚Œã€å¾Œã®åˆ†æã«å¿…è¦ãª Reactionæ•°ã‚„æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºä¿ã€‚")
                col1, col2, col3 = st.columns(3)
                col1.metric("äºˆæƒ³é‡è¤‡ç‡", "20-30%", "è¤‡æ•°æˆ¦ç•¥ã«ã‚ˆã‚‹")
                col2.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", "æœ€é«˜", "ãƒãƒ¼ã‚¸ãƒ§ãƒ³å†…å…¨ç¶²ç¾…")
                col3.metric("åŠ¹ç‡æ€§", "ä½", "åˆå›ã®ã¿å®Ÿè¡Œ")
            elif collection_mode == "incremental_newest":
                st.success("âš¡ **ç¶™ç¶šè¿½åŠ åé›†**: æŒ‡å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ Newest ã®ã¿å®Ÿè¡Œã—ã€æ–°ç€ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«è¿½åŠ ã€‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã® Reactionæƒ…å ±ã‚’æ´»ç”¨ã—ãŸåˆ†æãŒå¯èƒ½ã€‚é‡è¤‡ã‚’æœ€å°åŒ–ã€‚")
                col1, col2, col3 = st.columns(3)
                col1.metric("äºˆæƒ³é‡è¤‡ç‡", "0-5%", "æ–°ç€ã®ã¿å–å¾—")
                col2.metric("ãƒ‡ãƒ¼ã‚¿å“è³ª", "é«˜", "æ™‚ç³»åˆ—é †åºä¿æŒ")
                col3.metric("åŠ¹ç‡æ€§", "æœ€é«˜", "ç¶™ç¶šå®Ÿè¡Œæ¨å¥¨")

            # è©³ç´°è¨­å®š
            with st.expander("ğŸ› ï¸ è©³ç´°è¨­å®š"):
                col1, col2 = st.columns(2)

                with col1:
                    # NSFWãƒ¬ãƒ™ãƒ«è¨­å®š
                    if collection_mode == "initial_full_collection":
                        default_nsfw = ["Soft", "X"]
                    elif collection_mode == "incremental_newest":
                        default_nsfw = ["Soft", "X"]
                    elif collection_mode == "comprehensive_multi":
                        default_nsfw = ["Soft", "X"]
                    elif collection_mode == "nsfw_explicit_only":
                        default_nsfw = ["X"]
                    else:
                        default_nsfw = ["Soft"]

                    nsfw_levels = st.multiselect(
                        "NSFWãƒ¬ãƒ™ãƒ«ï¼ˆè¤‡æ•°é¸æŠæ¨å¥¨ï¼‰",
                        ["None", "Soft", "Mature", "X"],
                        default=default_nsfw,
                        help="X: æ˜ç¤ºçš„æ€§å™¨ãƒ»æ€§è¡Œç‚º, Mature: ç¤ºå”†çš„, Soft: è»½åº¦æ€§çš„"
                    )

                    # ã‚½ãƒ¼ãƒˆæˆ¦ç•¥
                    if collection_mode == "initial_full_collection":
                        default_sort = ["Most Reactions", "Newest"]
                        sort_help = "åˆå›åé›†: äººæ°—é †ã¨æ–°ç€é †ã§åŒ…æ‹¬çš„ã«ãƒ‡ãƒ¼ã‚¿åé›†"
                    elif collection_mode == "incremental_newest":
                        default_sort = ["Newest"]
                        sort_help = "ç¶™ç¶šåé›†: æ–°ç€ã®ã¿ã§åŠ¹ç‡çš„ã«æ›´æ–°ï¼ˆé‡è¤‡æœ€å°åŒ–ï¼‰"
                    else:
                        default_sort = ["Most Reactions", "Newest"]
                        sort_help = "CivitAI APIã§å®Ÿéš›ã«ä½¿ç”¨å¯èƒ½ãªã‚½ãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³"

                    sort_strategies = st.multiselect(
                        "ã‚½ãƒ¼ãƒˆæˆ¦ç•¥ï¼ˆAPIã§ä½¿ç”¨å¯èƒ½ãªã‚‚ã®ã®ã¿ï¼‰",
                        ["Most Reactions", "Newest", "Oldest"],
                        default=default_sort,
                        help=sort_help
                    )

                with col2:
                    # åé›†å¾Œã®åˆ†æè¨­å®š
                    st.info("ğŸ’¡ **åˆ†æè¨­å®š**\nåé›†ã¯NSFW+ã‚½ãƒ¼ãƒˆã®ã¿ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã¯åé›†å¾Œã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚")

                    # å¾Œå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                    post_analysis_options = st.multiselect(
                        "åé›†å¾Œè‡ªå‹•åˆ†æ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)",
                        [
                            "keyword_extraction", "nsfw_classification", "quality_scoring"
                        ],
                        default=["keyword_extraction", "nsfw_classification"],
                        format_func=lambda x: {
                            'keyword_extraction': 'ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ»åˆ†é¡',
                            'nsfw_classification': 'ğŸ¯ NSFW ãƒ¬ãƒ™ãƒ«è©³ç´°åˆ†æ',
                            'quality_scoring': 'â­ å“è³ªã‚¹ã‚³ã‚¢ç®—å‡º'
                        }.get(x, x),
                        help="åé›†å®Œäº†å¾Œã«å®Ÿè¡Œã™ã‚‹åˆ†æå‡¦ç†ã‚’é¸æŠ"
                    )

            # åé›†é‡è¨­å®š
            col1, col2, col3 = st.columns(3)
            with col1:
                enhanced_max_items = st.number_input("æˆ¦ç•¥ã‚ãŸã‚Šæœ€å¤§ä»¶æ•°", 50, 1000, 200, help="å„NSFWãƒ¬ãƒ™ãƒ«Ã—ã‚½ãƒ¼ãƒˆçµ„ã¿åˆã‚ã›ã®æœ€å¤§åé›†æ•°")
            with col2:
                enable_dedup = st.checkbox("é‡è¤‡é™¤å»", True, help="åŒä¸€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®é™¤å»")
            with col3:
                auto_categorize = st.checkbox("è‡ªå‹•åˆ†é¡", True, help="åé›†å¾Œã®è‡ªå‹•NSFWåˆ†é¡")

            # ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰è¿½åŠ 
            st.markdown("---")
            continuous_mode = st.checkbox(
                "ğŸ”„ ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰",
                value=True,
                help="å‰å›åé›†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ¯å›åŒã˜ä»¶æ•°ã§åé›†"
            )

            if continuous_mode:
                st.success("ğŸ’¡ ç¶™ç¶šãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹: æ¯å›åŒã˜ä»¶æ•°è¨­å®šã§æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‚’ç¶™ç¶šåé›†ã§ãã¾ã™")
            else:
                st.warning("âš ï¸ é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: é‡è¤‡ã«ã‚ˆã‚Š2å›ç›®ä»¥é™ã®åé›†æ•°ãŒæ¸›å°‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

            # å®Ÿè¡Œãƒœã‚¿ãƒ³
            enhanced_collect_button = st.button(
                "ğŸš€ åŠ¹ç‡çš„åé›†å®Ÿè¡Œ",
                type="primary",
                disabled=start_disabled,
                help="é¸æŠã—ãŸNSFWãƒ¬ãƒ™ãƒ«ãƒ»ã‚½ãƒ¼ãƒˆæˆ¦ç•¥ã§CivitAI APIã‹ã‚‰åŠ¹ç‡çš„ã«ãƒ‡ãƒ¼ã‚¿åé›†"
            )

            if enhanced_collect_button and version_id:
                with st.spinner("ï¿½ åŠ¹ç‡çš„åé›†ã‚’å®Ÿè¡Œä¸­..."):
                    try:
                        # Simple API-based collection for working UI
                        collection_results = {
                            'total_collected': 0,
                            'strategies_executed': 0,
                            'errors': []
                        }

                        # æˆ¦ç•¥åˆ¥çµæœè¨˜éŒ²ç”¨
                        strategy_results = []
                        total_saved_this_run = 0
                        total_fetched_this_run = 0

                        # Execute multiple strategies
                        for nsfw_level in nsfw_levels:
                            for sort_strategy in sort_strategies:
                                try:
                                    # ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€æ—¢å­˜ã®æœ€æ–°IDã‚’å–å¾—
                                    start_after_id = None
                                    # CivitAI APIã®åˆ¶é™: limitæœ€å¤§200
                                    actual_limit = min(enhanced_max_items, 200)

                                    # ç¶™ç¶šåé›†ç”¨ã®cursoræº–å‚™
                                    next_cursor = None
                                    if continuous_mode:
                                        try:
                                            # collection_stateãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æœ€å¾Œã®cursorã‚’å–å¾—
                                            db_temp = DatabaseManager(DEFAULT_DB_PATH)
                                            conn = db_temp._get_connection()
                                            cursor = conn.cursor()
                                            cursor.execute(
                                                """SELECT next_page_cursor FROM collection_state
                                                   WHERE version_id = ?
                                                   ORDER BY last_update DESC LIMIT 1""",
                                                (str(version_id),)
                                            )
                                            result = cursor.fetchone()
                                            if result and result[0]:
                                                next_cursor = result[0]
                                                st.write(f"ğŸ”„ ç¶™ç¶šãƒ¢ãƒ¼ãƒ‰: å‰å›ã®ç¶šãã‹ã‚‰åé›†ä¸­... (cursor: {next_cursor[:20]}...)")
                                            else:
                                                st.write(f"ğŸ”„ ç¶™ç¶šãƒ¢ãƒ¼ãƒ‰: åˆå›åé›†ã¾ãŸã¯å‰å›å®Œäº†æ¸ˆã¿")
                                            conn.close()
                                        except Exception as e:
                                            st.warning(f"ç¶™ç¶šåé›†æº–å‚™ã‚¨ãƒ©ãƒ¼: {e}")

                                    # Direct API call with NSFW parameters
                                    api_params = {
                                        'modelVersionId': version_id,
                                        'nsfw': nsfw_level,
                                        'sort': sort_strategy,
                                        'limit': actual_limit
                                    }

                                    # ç¶™ç¶šåé›†ç”¨ã®cursorãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¿½åŠ 
                                    if continuous_mode and next_cursor:
                                        api_params['cursor'] = next_cursor


                                    # Make API request (simplified)
                                    response = requests.get(
                                        "https://civitai.com/api/v1/images",
                                        params=api_params,
                                        timeout=30
                                    )

                                    if response.status_code == 200:
                                        data = response.json()
                                        items = data.get('items', [])

                                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å‡¦ç†ã‚’è¿½åŠ 
                                        saved_count = 0
                                        duplicate_count = 0
                                        error_count = 0
                                        db = DatabaseManager(DEFAULT_DB_PATH)

                                        # ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰ã§ã®çµæœç¢ºèª
                                        if continuous_mode:
                                            if items:
                                                st.write(f"ğŸ†• æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿: {len(items)}ä»¶å–å¾—ã—ã¾ã—ãŸ ({nsfw_level}+{sort_strategy})")
                                            else:
                                                st.info(f"ğŸ“­ ãƒ‡ãƒ¼ã‚¿ãªã—: ã“ã®ãƒšãƒ¼ã‚¸ã¯ç©ºã§ã™ ({nsfw_level}+{sort_strategy})")
                                                continue  # ã“ã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—

                                        for item in items:
                                            try:
                                                # Null ãƒã‚§ãƒƒã‚¯
                                                if item is None:
                                                    continue

                                                # å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿æŠ½å‡º
                                                item_id = item.get('id') if item else None
                                                if not item_id:
                                                    continue

                                                meta = item.get('meta') or {}
                                                stats = item.get('stats') or {}

                                                full_prompt = meta.get('prompt', '') if isinstance(meta, dict) else ''
                                                negative_prompt = meta.get('negativePrompt', '') if isinstance(meta, dict) else ''

                                                prompt_data = {
                                                    'civitai_id': str(item_id),
                                                    'full_prompt': full_prompt,
                                                    'negative_prompt': negative_prompt,
                                                    'model_version_id': str(version_id),
                                                    'model_id': str(item.get('modelVersionId', '') or ''),
                                                    'model_name': st.session_state.get('model_name_input', 'Unknown'),
                                                    'quality_score': stats.get('likeCount', 0) if isinstance(stats, dict) else 0,
                                                    'reaction_count': stats.get('reactionCount', 0) if isinstance(stats, dict) else 0,
                                                    'comment_count': stats.get('commentCount', 0) if isinstance(stats, dict) else 0,
                                                    'download_count': stats.get('downloadCount', 0) if isinstance(stats, dict) else 0,
                                                    'prompt_length': len(full_prompt) if full_prompt else 0,
                                                    'tag_count': len(full_prompt.split(',')) if full_prompt else 0,
                                                    'collected_at': datetime.now().isoformat(),
                                                    'raw_metadata': str(item)
                                                }

                                                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆçµæœã‚’è©³ç´°è¨˜éŒ²ï¼‰
                                                save_result = db.save_prompt_data(prompt_data)
                                                if save_result:
                                                    saved_count += 1
                                                else:
                                                    # ä¿å­˜å¤±æ•—ã®ç†ç”±ã‚’æ¨æ¸¬ï¼ˆé€šå¸¸ã¯é‡è¤‡ï¼‰
                                                    duplicate_count += 1
                                            except Exception as save_error:
                                                error_count += 1
                                                st.warning(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼ (Item ID: {item.get('id', 'Unknown') if item else 'None'}): {save_error}")

                                        # æˆ¦ç•¥åˆ¥çµæœè¨˜éŒ²
                                        strategy_result = {
                                            'strategy': f"{nsfw_level}+{sort_strategy}",
                                            'fetched': len(items),
                                            'saved': saved_count,
                                            'duplicates': duplicate_count,
                                            'errors': error_count
                                        }
                                        strategy_results.append(strategy_result)

                                        collection_results['total_collected'] += len(items)
                                        collection_results['strategies_executed'] += 1
                                        total_saved_this_run += saved_count
                                        total_fetched_this_run += len(items)

                                        # ç¶™ç¶šåé›†ç”¨ã®nextCursorã‚’ä¿å­˜
                                        if continuous_mode:
                                            try:
                                                metadata = data.get('metadata', {})
                                                next_cursor_to_save = metadata.get('nextCursor')
                                                if next_cursor_to_save:
                                                    db_temp = DatabaseManager(DEFAULT_DB_PATH)
                                                    conn = db_temp._get_connection()
                                                    cursor = conn.cursor()
                                                    cursor.execute(
                                                        """UPDATE collection_state
                                                           SET next_page_cursor = ?, last_update = datetime('now')
                                                           WHERE version_id = ?""",
                                                        (next_cursor_to_save, str(version_id))
                                                    )
                                                    conn.commit()
                                                    conn.close()
                                            except Exception as e:
                                                st.warning(f"nextCursorä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

                                        # æˆ¦ç•¥åˆ¥çµæœè¡¨ç¤ºï¼ˆè©³ç´°ç‰ˆï¼‰
                                        if duplicate_count > 0:
                                            st.write(f"âœ… {nsfw_level}+{sort_strategy}: {len(items)}ä»¶å–å¾—ã€{saved_count}ä»¶ä¿å­˜ã€{duplicate_count}ä»¶é‡è¤‡ã‚¹ã‚­ãƒƒãƒ—")
                                        else:
                                            st.write(f"âœ… {nsfw_level}+{sort_strategy}: {len(items)}ä»¶å–å¾—ã€{saved_count}ä»¶ä¿å­˜")
                                    else:
                                        # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’å–å¾—
                                        try:
                                            error_detail = response.json()
                                            error_msg = f"{nsfw_level}+{sort_strategy}: HTTP {response.status_code} - {error_detail.get('error', {}).get('message', 'Unknown error')}"
                                        except:
                                            error_msg = f"{nsfw_level}+{sort_strategy}: HTTP {response.status_code}"

                                        collection_results['errors'].append(error_msg)
                                        st.error(error_msg)

                                    time.sleep(0.5)  # APIåˆ¶é™å¯¾ç­–

                                except Exception as e:
                                    error_msg = f"{nsfw_level}+{sort_strategy}: {str(e)}"
                                    collection_results['errors'].append(error_msg)
                                    st.error(error_msg)

                        # çµæœè¡¨ç¤ºã®æ”¹å–„
                        st.success(f"ğŸ‰ åŒ…æ‹¬çš„åé›†å®Œäº†ï¼")

                        # ãƒ¡ã‚¤ãƒ³ã®çµæœè¡¨ç¤ºï¼ˆä»Šå›ã®å®Ÿè¡Œçµæœã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ï¼‰
                        col1, col2, col3 = st.columns(3)
                        col1.metric("ğŸ¯ ä»Šå›ä¿å­˜æˆåŠŸ", f"{total_saved_this_run}ä»¶", help="ã“ã®å®Ÿè¡Œã§å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã•ã‚ŒãŸä»¶æ•°")
                        col2.metric("ğŸ“¥ ä»Šå›å–å¾—ç·ä»¶æ•°", f"{total_fetched_this_run}ä»¶", help="ã“ã®å®Ÿè¡Œã§CivitAI APIã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ä»¶æ•°")
                        col3.metric("âš™ï¸ å®Ÿè¡Œæˆ¦ç•¥æ•°", f"{collection_results['strategies_executed']}å€‹", help="å®Ÿè¡Œã•ã‚ŒãŸåé›†æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›æ•°")

                        # ä¿å­˜ã•ã‚Œãªã‹ã£ãŸä»¶æ•°ã¨ãã®ç†ç”±
                        not_saved = total_fetched_this_run - total_saved_this_run
                        if not_saved > 0:
                            total_duplicates = sum(sr['duplicates'] for sr in strategy_results)
                            total_errors = sum(sr['errors'] for sr in strategy_results)

                            st.markdown("#### ğŸ” ä¿å­˜ã•ã‚Œãªã‹ã£ãŸç†ç”±ã®å†…è¨³")
                            col_dup, col_err, col_other = st.columns(3)
                            col_dup.metric("ğŸ” é‡è¤‡ãƒ‡ãƒ¼ã‚¿", f"{total_duplicates}ä»¶", help="æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã—ã¦ã„ãŸãŸã‚ä¿å­˜ã•ã‚Œãªã‹ã£ãŸ")
                            col_err.metric("âŒ ã‚¨ãƒ©ãƒ¼", f"{total_errors}ä»¶", help="ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚„ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã§ä¿å­˜ã«å¤±æ•—")
                            col_other.metric("â“ ãã®ä»–", f"{not_saved - total_duplicates - total_errors}ä»¶", help="ãã®ä»–ã®ç†ç”±ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã€å¿…é ˆé …ç›®ä¸è¶³ç­‰ï¼‰")

                            st.info(f"""
                            **ğŸ’¡ ä¿å­˜ã•ã‚Œãªã‹ã£ãŸ{not_saved}ä»¶ã«ã¤ã„ã¦:**
                            - **é‡è¤‡ãƒ‡ãƒ¼ã‚¿**: {total_duplicates}ä»¶ â†’ æ—¢ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å­˜åœ¨ã™ã‚‹ãŸã‚æ­£å¸¸ã«ã‚¹ã‚­ãƒƒãƒ—
                            - **ã‚¨ãƒ©ãƒ¼**: {total_errors}ä»¶ â†’ ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®å•é¡Œç­‰ã§ä¿å­˜å¤±æ•—
                            - **ãã®ä»–**: {not_saved - total_duplicates - total_errors}ä»¶ â†’ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã€å¿…é ˆé …ç›®ä¸è¶³ç­‰

                            **é‡è¤‡ãŒå¤šã„ç†ç”±**: ç¶™ç¶šåé›†ãƒ¢ãƒ¼ãƒ‰ã§ã¯åŒã˜ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯æ­£å¸¸ãªå‹•ä½œã§ã™ã€‚
                            """)

                        # æˆ¦ç•¥åˆ¥è©³ç´°çµæœ
                        if strategy_results:
                            with st.expander("ğŸ“Š æˆ¦ç•¥åˆ¥è©³ç´°çµæœ", expanded=False):
                                for sr in strategy_results:
                                    st.write(f"**{sr['strategy']}**: å–å¾—{sr['fetched']}ä»¶ â†’ ä¿å­˜{sr['saved']}ä»¶ï¼ˆé‡è¤‡{sr['duplicates']}ä»¶ã€ã‚¨ãƒ©ãƒ¼{sr['errors']}ä»¶ï¼‰")

                        # è©³ç´°èª¬æ˜
                        st.markdown("#### ğŸ“‹ åé›†çµæœã¾ã¨ã‚")
                        if total_saved_this_run > 0:
                            st.success(f"""
                            **âœ… æˆåŠŸ**: ä»Šå›{total_saved_this_run}ä»¶ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã—ãŸï¼
                            **ğŸ”„ ç¶™ç¶šåé›†**: æ¬¡å›å®Ÿè¡Œæ™‚ã¯ã•ã‚‰ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚
                            """)
                        else:
                            st.warning(f"""
                            **â„¹ï¸ çµæœ**: ä»Šå›æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚
                            **ğŸ’¡ ç†ç”±**: å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦é‡è¤‡ã¾ãŸã¯ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
                            """)

                        if collection_results['errors']:
                            with st.expander("âš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´°"):
                                for error in collection_results['errors']:
                                    st.write(f"- {error}")

                    except Exception as e:
                        st.error(f"åŒ…æ‹¬çš„åé›†ã§ã‚¨ãƒ©ãƒ¼: {e}")

            # ç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆè¡¨ç¤º
            with st.expander("ğŸ“Š åé›†çµ±è¨ˆäºˆæ¸¬"):
                st.markdown("**CivitAI APIåˆ¶ç´„ã«åŸºã¥ãäºˆæƒ³åé›†æ•°:**")

                # æˆ¦ç•¥æ•°ã®è¨ˆç®—
                strategy_count = len(nsfw_levels) * len(sort_strategies)
                st.metric("å®Ÿè¡Œæˆ¦ç•¥æ•°", f"{strategy_count}å€‹", f"NSFW{len(nsfw_levels)}ç¨® Ã— ã‚½ãƒ¼ãƒˆ{len(sort_strategies)}ç¨®")

                if enhanced_max_items:
                    total_max = strategy_count * enhanced_max_items
                    if collection_mode == "incremental_newest":
                        expected_duplicates = "0-5%"
                        expected_saved = int(total_max * 0.975)  # 97.5%ä¿å­˜äºˆæƒ³
                    else:
                        expected_duplicates = "20-30%"
                        expected_saved = int(total_max * 0.75)   # 75%ä¿å­˜äºˆæƒ³

                    col1, col2 = st.columns(2)
                    col1.metric("äºˆæƒ³å–å¾—æ•°", f"{total_max:,}ä»¶", f"æˆ¦ç•¥ã‚ãŸã‚Š{enhanced_max_items}ä»¶")
                    col2.metric("äºˆæƒ³ä¿å­˜æ•°", f"{expected_saved:,}ä»¶", f"é‡è¤‡ç‡{expected_duplicates}")

        except Exception as e:
            st.warning(f"NSFWåé›†æ©Ÿèƒ½ã§ã‚¨ãƒ©ãƒ¼: {e}")
            st.info("å¾“æ¥ã®åé›†æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„")

    with tab1:
        st.header("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("è¡¨ç¤ºä¸­ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", len(df))
        with col2:
            if 'confidence' in df.columns:
                avg_confidence = df['confidence'].mean()
                st.metric("å¹³å‡ä¿¡é ¼åº¦", f"{avg_confidence:.2f}")
            else:
                st.metric("å¹³å‡ä¿¡é ¼åº¦", "N/A")
        with col3:
            unique_models = df['model_name'].nunique()
            st.metric("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æ•°", unique_models)
        with col4:
            if 'category' in df.columns:
                categories_count = df['category'].nunique()
                st.metric("ã‚«ãƒ†ã‚´ãƒªæ•°", categories_count)
            else:
                st.metric("ã‚«ãƒ†ã‚´ãƒªæ•°", "æœªå®Ÿè£…")

        col1, col2 = st.columns(2)
        with col1:
            pie_chart = create_category_distribution_chart(df)
            if pie_chart:
                display_chart(pie_chart)
        with col2:
            hist_chart = create_confidence_histogram(df)
            if hist_chart:
                display_chart(hist_chart)

    with tab2:
        st.header("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§")
        page_size = 50
        total_items = len(df)
        total_pages = max(1, math.ceil(total_items / page_size))
        colp1, colp2 = st.columns([1, 3])
        with colp1:
            page = st.number_input("ãƒšãƒ¼ã‚¸", min_value=1, max_value=total_pages, value=1, step=1, format="%d")
        with colp2:
            st.write(f"è¡¨ç¤º: {page_size} ä»¶/ãƒšãƒ¼ã‚¸ â€” åˆè¨ˆ {total_items} ä»¶ / å…¨ {total_pages} ãƒšãƒ¼ã‚¸")
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        display_df = df.iloc[start_idx:end_idx]
        st.write(f"è¡¨ç¤ºä¸­: {len(display_df)} / {len(df)} ä»¶ (ãƒšãƒ¼ã‚¸ {page}/{total_pages})")
        for idx, row in display_df.iterrows():
            display_prompt_card(row)

    with tab3:
        st.header("è©³ç´°åˆ†æ")
        try:
            # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—ã—ã¦ç¢ºå®Ÿã«åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹
            current_stats = get_database_stats()
            if 'category_stats' in current_stats and not current_stats['category_stats'].empty:
                st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ")
                try:
                    category_chart = px.bar(current_stats['category_stats'], x='category', y='count', title='ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°', labels={'count': 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°', 'category': 'ã‚«ãƒ†ã‚´ãƒª'}, color='avg_confidence', color_continuous_scale='viridis')
                    display_chart(category_chart)
                except Exception:
                    st.write(current_stats['category_stats'])
        except Exception as e:
            pass  # ã‚«ãƒ†ã‚´ãƒªçµ±è¨ˆãŒãªã„å ´åˆã¯é™ã‹ã«ã‚¹ã‚­ãƒƒãƒ—

        # ğŸ” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ åˆ†æ - æ–°æ©Ÿèƒ½è¿½åŠ 
        st.subheader("ğŸ” ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ åˆ†æ")
        if not df.empty and 'full_prompt' in df.columns:
            try:
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æ
                valid_prompts = df[df['full_prompt'].notna() & (df['full_prompt'] != '')]
                total_prompts = len(valid_prompts)

                if total_prompts > 0:
                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºæ™‚ã®ã¿ - æœ¬ç•ªã§ã¯éè¡¨ç¤ºï¼‰
                    if False:  # ãƒ‡ãƒãƒƒã‚°ãƒ•ãƒ©ã‚° - å¿…è¦æ™‚ã«Trueã«å¤‰æ›´
                        with st.expander("ğŸ”§ ãƒ‡ãƒãƒƒã‚°æƒ…å ±", expanded=False):
                            st.write(f"DataFrameã‚«ãƒ©ãƒ æ•°: {len(df.columns)}")
                            st.write(f"åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {list(df.columns)}")
                            st.write(f"total_prompts: {total_prompts}")
                            if 'prompt_length' in df.columns:
                                st.write(f"prompt_lengthã‚«ãƒ©ãƒ å­˜åœ¨: âœ…")
                                st.write(f"prompt_lengthéNULLæ•°: {df['prompt_length'].notna().sum()}")
                            else:
                                st.write(f"prompt_lengthã‚«ãƒ©ãƒ å­˜åœ¨: âŒ")

                    # æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                    comma_separated = len(valid_prompts[valid_prompts['full_prompt'].str.contains(',', na=False)])
                    weight_usage = len(valid_prompts[valid_prompts['full_prompt'].str.contains(r':\s*\d+\.?\d*', regex=True, na=False)])
                    parentheses_usage = len(valid_prompts[valid_prompts['full_prompt'].str.contains(r'[(\[]', regex=True, na=False)])
                    embedding_usage = len(valid_prompts[valid_prompts['full_prompt'].str.contains(r'<[^>]+>', regex=True, na=False)])

                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric(
                            "ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šä½¿ç”¨ç‡",
                            f"{comma_separated/total_prompts*100:.1f}%",
                            f"{comma_separated}/{total_prompts}"
                        )

                    with col2:
                        st.metric(
                            "é‡ã¿ä»˜ã‘è¨˜æ³•",
                            f"{weight_usage/total_prompts*100:.1f}%",
                            f"{weight_usage}/{total_prompts}"
                        )

                    with col3:
                        st.metric(
                            "æ‹¬å¼§ä½¿ç”¨ç‡",
                            f"{parentheses_usage/total_prompts*100:.1f}%",
                            f"{parentheses_usage}/{total_prompts}"
                        )

                    with col4:
                        st.metric(
                            "ã‚¨ãƒ³ãƒ™ãƒƒãƒ‡ã‚£ãƒ³ã‚°",
                            f"{embedding_usage/total_prompts*100:.1f}%",
                            f"{embedding_usage}/{total_prompts}"
                        )

                    # é•·ã•åˆ†å¸ƒåˆ†æ
                    st.subheader("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•çµ±è¨ˆ")

                    # prompt_lengthã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèªã¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†
                    if 'prompt_length' in df.columns:
                        length_data = df['prompt_length'].dropna()
                    else:
                        # prompt_lengthãŒç„¡ã„å ´åˆã¯å‹•çš„è¨ˆç®—ï¼ˆé™ã‹ã«å®Ÿè¡Œï¼‰
                        length_data = valid_prompts['full_prompt'].str.len()

                    if len(length_data) > 0:
                        col_left, col_right = st.columns(2)

                        with col_left:
                            st.write("**åŸºæœ¬çµ±è¨ˆ**")
                            st.metric("å¹³å‡æ–‡å­—æ•°", f"{length_data.mean():.1f}")
                            st.metric("ä¸­å¤®å€¤", f"{length_data.median():.1f}")
                            st.write(f"æœ€çŸ­: **{length_data.min()}** æ–‡å­—")
                            st.write(f"æœ€é•·: **{length_data.max()}** æ–‡å­—")
                            st.write(f"æ¨™æº–åå·®: **{length_data.std():.1f}**")

                        with col_right:
                            # é•·ã•åˆ†å¸ƒã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
                            try:
                                if PLOTLY_AVAILABLE:
                                    # DataFrameã‚’ä½œæˆã—ã¦plotlyç”¨ã«æ•´å½¢
                                    hist_df = pd.DataFrame({'prompt_length': length_data})
                                    length_hist = px.histogram(
                                        hist_df,
                                        x='prompt_length',
                                        nbins=min(20, len(length_data.unique())),
                                        title='ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•åˆ†å¸ƒ',
                                        labels={'prompt_length': 'æ–‡å­—æ•°', 'count': 'ä»¶æ•°'}
                                    )
                                    display_chart(length_hist)
                                else:
                                    # PlotlyãŒç„¡ã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                                    st.write("**é•·ã•åˆ†å¸ƒ**")
                                    length_counts = length_data.value_counts().sort_index()
                                    st.bar_chart(length_counts.head(10))
                            except Exception as e:
                                st.warning(f"ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")
                                # ã‚·ãƒ³ãƒ—ãƒ«ãªçµ±è¨ˆè¡¨ç¤º
                                st.write("**é•·ã•ç¯„å›²åˆ¥åˆ†å¸ƒ**")
                                bins = [0, 100, 300, 500, 1000, float('inf')]
                                labels = ['0-99', '100-299', '300-499', '500-999', '1000+']
                                length_ranges = pd.cut(length_data, bins=bins, labels=labels, include_lowest=True)
                                range_counts = length_ranges.value_counts()
                                st.write(range_counts)
                    else:
                        st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                    # ComfyUIé€£æºã®ãƒ’ãƒ³ãƒˆ
                    st.info("""
                    ğŸ’¡ **ComfyUIé€£æºã®ãƒã‚¤ãƒ³ãƒˆ**
                    - **97%ä»¥ä¸Š**ãŒã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š â†’ ãƒ‘ãƒ¼ã‚µãƒ¼ã¯ã‚«ãƒ³ãƒãƒ™ãƒ¼ã‚¹å®Ÿè£…ã‚’æ¨å¥¨
                    - **50%ä»¥ä¸Š**ãŒé‡ã¿ä»˜ã‘ä½¿ç”¨ â†’ `:æ•°å€¤` ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‡¦ç†ãŒé‡è¦
                    - æ‹¬å¼§ä½¿ç”¨ãŒå¤šã„å ´åˆ â†’ ã‚°ãƒ«ãƒ¼ãƒ—åŒ–æ©Ÿèƒ½ã®å®Ÿè£…ã‚’æ¤œè¨
                    """)

                else:
                    st.warning("æœ‰åŠ¹ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            except Exception as e:
                st.error(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

        # ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªç›¸é–¢åˆ†æ - æ–°æ©Ÿèƒ½è¿½åŠ 
        st.subheader("ğŸ¯ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªç›¸é–¢åˆ†æ")
        if not df.empty and 'full_prompt' in df.columns and 'quality_score' in df.columns:
            try:
                valid_prompts = df[df['full_prompt'].notna() & (df['full_prompt'] != '')]

                if len(valid_prompts) > 0:
                    # å“è³ªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©
                    quality_keywords = [
                        'masterpiece', 'best quality', 'high quality', 'detailed', 'ultra detailed',
                        'realistic', 'photorealistic', '8k', '4k', 'high resolution',
                        'cinematic', 'dramatic', 'lighting', 'depth of field', 'sharp',
                        'beautiful', 'stunning', 'amazing', 'incredible', 'perfect'
                    ]

                    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©
                    style_keywords = [
                        'anime', 'realistic', 'portrait', 'landscape', 'abstract',
                        'oil painting', 'watercolor', 'digital art', 'concept art', 'cartoon'
                    ]

                    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æå®Ÿè¡Œ
                    keyword_analysis = {}

                    for keyword in quality_keywords + style_keywords:
                        # ãã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        contains_keyword = valid_prompts[
                            valid_prompts['full_prompt'].str.lower().str.contains(keyword, na=False)
                        ]

                        if len(contains_keyword) >= 5:  # æœ€ä½5ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
                            avg_quality = contains_keyword['quality_score'].mean()
                            count = len(contains_keyword)
                            max_quality = contains_keyword['quality_score'].max()

                            keyword_analysis[keyword] = {
                                'count': count,
                                'avg_quality': avg_quality,
                                'max_quality': max_quality
                            }

                    if keyword_analysis:
                        # å“è³ªé †ã«ã‚½ãƒ¼ãƒˆ
                        sorted_keywords = sorted(keyword_analysis.items(),
                                               key=lambda x: x[1]['avg_quality'], reverse=True)

                        col_left, col_right = st.columns(2)

                        with col_left:
                            st.write("**ğŸ† é«˜å“è³ªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP10**")
                            for i, (keyword, stats) in enumerate(sorted_keywords[:10]):
                                st.write(f"{i+1}. **{keyword}**: {stats['avg_quality']:.1f}ç‚¹ ({stats['count']}ä»¶)")

                        with col_right:
                            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªæ•£å¸ƒå›³
                            try:
                                if PLOTLY_AVAILABLE and len(sorted_keywords) >= 3:
                                    # æ•£å¸ƒå›³ç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™
                                    scatter_data = []
                                    for keyword, stats in sorted_keywords[:15]:  # ä¸Šä½15å€‹
                                        scatter_data.append({
                                            'keyword': keyword,
                                            'count': stats['count'],
                                            'avg_quality': stats['avg_quality'],
                                            'max_quality': stats['max_quality']
                                        })

                                    scatter_df = pd.DataFrame(scatter_data)

                                    scatter_fig = px.scatter(
                                        scatter_df,
                                        x='count',
                                        y='avg_quality',
                                        size='max_quality',
                                        hover_name='keyword',
                                        title='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨é »åº¦ vs å¹³å‡å“è³ª',
                                        labels={'count': 'ä½¿ç”¨å›æ•°', 'avg_quality': 'å¹³å‡å“è³ªã‚¹ã‚³ã‚¢'}
                                    )
                                    display_chart(scatter_fig)
                                else:
                                    st.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆï¼ˆç°¡æ˜“è¡¨ç¤ºï¼‰**")
                                    for keyword, stats in sorted_keywords[:5]:
                                        st.write(f"â€¢ {keyword}: {stats['avg_quality']:.1f}ç‚¹")
                            except Exception as e:
                                st.write("**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºï¼‰**")
                                for keyword, stats in sorted_keywords[:8]:
                                    st.write(f"â€¢ {keyword}: {stats['avg_quality']:.1f}ç‚¹ ({stats['count']}ä»¶)")

                        # ComfyUIæ´»ç”¨ææ¡ˆ
                        if sorted_keywords:
                            top_keywords = [kw[0] for kw in sorted_keywords[:5]]
                            st.success(f"""
                            ğŸ’¡ **ComfyUI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®ææ¡ˆ**

                            **é«˜å“è³ªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ´»ç”¨:**
                            - ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ : `{', '.join(top_keywords[:3])}`
                            - å“è³ªå‘ä¸Šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: `masterpiece, best quality, {top_keywords[0]}`
                            - æ¡ä»¶ä»˜ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: å“è³ªã‚¹ã‚³ã‚¢{sorted_keywords[0][1]['avg_quality']:.0f}+ã‚’ç›®æŒ‡ã™å ´åˆ
                            """)
                    else:
                        st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆå„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æœ€ä½5ä»¶å¿…è¦ï¼‰")

            except Exception as e:
                st.error(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.warning("å“è³ªåˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»å“è³ªã‚¹ã‚³ã‚¢ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

        st.subheader("ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ")
        model_stats = df['model_name'].value_counts().head(10)
        try:
            model_chart = px.bar(x=model_stats.values, y=model_stats.index, orientation='h', title='ä¸Šä½10ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨é »åº¦', labels={'x': 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°', 'y': 'ãƒ¢ãƒ‡ãƒ«å'})
            display_chart(model_chart)
        except Exception:
            st.write(model_stats)

        # ğŸ“ˆ åé›†æˆ¦ç•¥æ¨å¥¨ - æ–°æ©Ÿèƒ½è¿½åŠ 
        st.subheader("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³åé›†æˆ¦ç•¥æ¨å¥¨")
        if not df.empty:
            try:
                total_prompts = len(df)
                avg_quality = df['quality_score'].mean() if 'quality_score' in df.columns else 0

                col1, col2 = st.columns(2)

                with col1:
                    st.write("**ğŸ“Š ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿çŠ¶æ³**")
                    st.metric("ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", f"{total_prompts:,}")
                    if 'quality_score' in df.columns:
                        st.metric("å¹³å‡å“è³ªã‚¹ã‚³ã‚¢", f"{avg_quality:.1f}")

                        # å“è³ªåˆ†å¸ƒåˆ†æ
                        high_quality_count = len(df[df['quality_score'] >= 100])
                        high_quality_rate = (high_quality_count / total_prompts) * 100 if total_prompts > 0 else 0
                        st.metric("é«˜å“è³ªç‡ (100+)", f"{high_quality_rate:.1f}%")

                with col2:
                    st.write("**ğŸ¯ åé›†æˆ¦ç•¥ææ¡ˆ**")

                    # ãƒ‡ãƒ¼ã‚¿é‡ã«åŸºã¥ãææ¡ˆ
                    if total_prompts < 500:
                        st.warning("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³: 1,000ä»¶ä»¥ä¸Šã®åé›†ã‚’æ¨å¥¨")
                    elif total_prompts < 1000:
                        st.info("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é‡ã‚„ã‚„ä¸è¶³: ã•ã‚‰ãªã‚‹åé›†ã§ç²¾åº¦å‘ä¸Š")
                    else:
                        st.success("ğŸ“Š ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã‚’ç¢ºä¿")

                    # å“è³ªã«åŸºã¥ãææ¡ˆ
                    if 'quality_score' in df.columns:
                        if avg_quality < 50:
                            st.warning("â­ å“è³ªå‘ä¸ŠãŒå¿…è¦: é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ(100+)ã‚’å„ªå…ˆåé›†")
                        elif avg_quality < 100:
                            st.info("â­ å“è³ªã¯æ¨™æº–ãƒ¬ãƒ™ãƒ«: ã‚ˆã‚Šé«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã®åé›†ã‚’æ¤œè¨")
                        else:
                            st.success("â­ é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºä¿")

                # å…·ä½“çš„ãªæ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                st.write("**ğŸš€ æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨**")

                recommendations = []

                if total_prompts < 1000:
                    recommendations.append("ğŸ”„ **ç¶™ç¶šåé›†**: ã€ŒğŸ” åé›†ã€ã‚¿ãƒ–ã§åŠ¹ç‡çš„åé›†æˆ¦ç•¥ã‚’å®Ÿè¡Œ")

                if 'quality_score' in df.columns and avg_quality < 100:
                    recommendations.append("â­ **å“è³ªãƒ•ã‚£ãƒ«ã‚¿**: quality_score >= 100 ã®æ¡ä»¶ã§é«˜å“è³ªãƒ‡ãƒ¼ã‚¿ã‚’é‡ç‚¹åé›†")

                if len(df['model_name'].unique()) < 3:
                    recommendations.append("ğŸ¤– **ãƒ¢ãƒ‡ãƒ«å¤šæ§˜åŒ–**: è¤‡æ•°ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿åé›†")

                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¤šæ§˜æ€§ãƒã‚§ãƒƒã‚¯
                if 'full_prompt' in df.columns:
                    unique_keywords_estimate = len(set(' '.join(df['full_prompt'].fillna('').str.lower()).split()))
                    if unique_keywords_estimate < 1000:
                        recommendations.append("ğŸ·ï¸ **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¤šæ§˜åŒ–**: ç•°ãªã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ãƒ†ãƒ¼ãƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåé›†")

                if not recommendations:
                    recommendations.append("âœ… **ç¾çŠ¶ç¶­æŒ**: è‰¯å¥½ãªãƒ‡ãƒ¼ã‚¿åé›†çŠ¶æ³ã§ã™")

                for i, rec in enumerate(recommendations, 1):
                    st.write(f"{i}. {rec}")

                # ComfyUIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ææ¡ˆ
                if 'quality_score' in df.columns and avg_quality >= 50:
                    st.info("""
                    ğŸ”§ **ComfyUIãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆææ¡ˆ**
                    - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè‡ªå‹•è£œå®Œ: é«˜å“è³ªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è‡ªå‹•è¿½åŠ 
                    - å“è³ªäºˆæ¸¬ãƒãƒ¼ãƒ‰: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å“è³ªã‚¹ã‚³ã‚¢äºˆæ¸¬
                    - ã‚¹ã‚¿ã‚¤ãƒ«æ¨å¥¨: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é¡ä¼¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ææ¡ˆ
                    """)

            except Exception as e:
                st.error(f"åé›†æˆ¦ç•¥åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
        else:
            st.warning("åˆ†æã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

    with tab4:
        st.header("ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        export_df = df.copy()
        available_columns = export_df.columns.tolist()
        selected_columns = st.multiselect("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ", options=available_columns, default=available_columns, key='selected_columns')
        if selected_columns:
            export_df = export_df[selected_columns]
        st.subheader("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(export_df.head(5), use_container_width=True)
        csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_data, file_name=f"civitai_prompts_{len(export_df)}ä»¶.csv", mime="text/csv")
        st.info(f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯¾è±¡: {len(export_df)} ä»¶")

if __name__ == "__main__":
    main()

