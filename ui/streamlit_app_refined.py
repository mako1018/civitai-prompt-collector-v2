"""
CivitAI Prompt Collector - å®Ÿç”¨çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«
æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç´°åˆ†åŒ–ã¨ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºæ©Ÿèƒ½
"""
import streamlit as st
import sqlite3
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
from collections import Counter
import numpy as np
from pathlib import Path
import sys
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã¨DBãƒ‘ã‚¹å®šç¾©
project_root = Path(__file__).parent.parent
DEFAULT_DB_PATH = str(project_root / 'data' / 'civitai_dataset.db')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Civitai ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .metric-container {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    .category-badge {
        background-color: #e1f5fe;
        color: #01579b;
        padding: 0.2rem 0.5rem;
        border-radius: 15px;
        font-size: 0.8rem;
        margin: 0.1rem;
        display: inline-block;
    }
    .prompt-card {
        background-color: #ffffff;
        border-left: 4px solid #1f77b4;
        padding: 1rem;
        margin: 0.5rem 0;
        border-radius: 5px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .quality-high { color: #4caf50; font-weight: bold; }
    .quality-medium { color: #ff9800; font-weight: bold; }
    .quality-low { color: #f44336; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_prompt_data():
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    try:
        conn = sqlite3.connect(DEFAULT_DB_PATH)
        
        query = """
        SELECT 
            id,
            civitai_id,
            full_prompt,
            negative_prompt,
            quality_score,
            reaction_count,
            comment_count,
            download_count,
            prompt_length,
            tag_count,
            model_name,
            model_id,
            collected_at,
            model_version_id
        FROM civitai_prompts 
        WHERE full_prompt IS NOT NULL AND full_prompt != ''
        ORDER BY quality_score DESC
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®èª¿æ•´
        numeric_columns = ['quality_score', 'reaction_count', 'comment_count', 'download_count', 'prompt_length', 'tag_count']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã®å†è¨ˆç®—ï¼ˆä¸æ­£ãªå€¤ã®å ´åˆï¼‰
        mask = df['prompt_length'] <= 0
        df.loc[mask, 'prompt_length'] = df.loc[mask, 'full_prompt'].str.len()
        
        return df
        
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def categorize_prompt_by_content(prompt_text):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å†…å®¹ã«åŸºã¥ã„ã¦ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º"""
    if not prompt_text:
        return "æœªåˆ†é¡", 0.0
    
    prompt_lower = prompt_text.lower()
    
    # ã‚«ãƒ†ã‚´ãƒªå®šç¾©
    categories = {
        "ãƒãƒ¼ãƒˆãƒ¬ãƒ¼ãƒˆ": ["portrait", "face", "headshot", "closeup", "person", "woman", "man", "girl", "boy"],
        "é¢¨æ™¯": ["landscape", "scenery", "nature", "mountain", "forest", "ocean", "sky", "sunset", "sunrise"],
        "ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚¤ãƒ©ã‚¹ãƒˆ": ["anime", "manga", "cartoon", "illustration", "2d", "cel shading", "kawaii"],
        "ãƒªã‚¢ãƒ«å†™çœŸ": ["realistic", "photorealistic", "photography", "photo", "camera", "lens"],
        "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼": ["fantasy", "magic", "dragon", "wizard", "fairy", "medieval", "castle"],
        "ã‚µã‚¤ãƒ•ã‚¡ã‚¤": ["sci-fi", "futuristic", "robot", "cyberpunk", "space", "alien", "technology"],
        "ãƒ›ãƒ©ãƒ¼": ["horror", "scary", "dark", "gothic", "vampire", "zombie", "creepy"],
        "ã‚¢ãƒ¼ãƒˆ": ["artistic", "painting", "drawing", "sketch", "watercolor", "oil painting"],
        "å»ºç¯‰": ["architecture", "building", "house", "interior", "room", "design"],
        "å‹•ç‰©": ["animal", "cat", "dog", "horse", "bird", "wildlife"]
    }
    
    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
    category_scores = {}
    for category, keywords in categories.items():
        score = sum(1 for keyword in keywords if keyword in prompt_lower)
        if score > 0:
            category_scores[category] = score / len(keywords)
    
    if category_scores:
        best_category = max(category_scores, key=category_scores.get)
        confidence = category_scores[best_category]
        return best_category, confidence
    
    return "æœªåˆ†é¡", 0.0

def analyze_prompt_complexity(prompt_text):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¤‡é›‘åº¦ã‚’åˆ†æ"""
    if not prompt_text:
        return "ç°¡å˜", 0
    
    # è¤‡é›‘åº¦æŒ‡æ¨™
    length = len(prompt_text)
    comma_count = prompt_text.count(',')
    parentheses_count = prompt_text.count('(') + prompt_text.count(')')
    weight_count = len(re.findall(r':\s*\d*\.?\d+', prompt_text))
    
    # è¤‡é›‘åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
    complexity_score = (
        length / 100 * 2 +  # é•·ã•
        comma_count * 1 +   # è¦ç´ æ•°
        parentheses_count * 0.5 +  # æ‹¬å¼§
        weight_count * 2    # é‡ã¿æŒ‡å®š
    )
    
    if complexity_score < 5:
        return "ç°¡å˜", complexity_score
    elif complexity_score < 15:
        return "æ™®é€š", complexity_score
    elif complexity_score < 30:
        return "è¤‡é›‘", complexity_score
    else:
        return "éå¸¸ã«è¤‡é›‘", complexity_score

def extract_top_keywords(df, min_frequency=5, max_keywords=50):
    """é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    all_keywords = []
    
    for prompt in df['full_prompt'].dropna():
        # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§åˆ†å‰²ã—ã¦æ­£è¦åŒ–
        elements = [elem.strip().lower() for elem in prompt.split(',')]
        
        for elem in elements:
            # é‡ã¿æŒ‡å®šã‚„æ‹¬å¼§ã‚’é™¤å»
            elem = re.sub(r':\s*\d*\.?\d+', '', elem)
            elem = re.sub(r'[\(\)\[\]{}]', '', elem)
            elem = elem.strip()
            
            if elem and len(elem) > 2 and not elem.isdigit():
                all_keywords.append(elem)
    
    # é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
    keyword_counts = Counter(all_keywords)
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    filtered_keywords = {
        k: v for k, v in keyword_counts.most_common(max_keywords) 
        if v >= min_frequency
    }
    
    return filtered_keywords

def analyze_quality_patterns(df):
    """å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
    if df.empty:
        return {}
    
    # å“è³ªãƒ¬ãƒ™ãƒ«ã®å®šç¾©
    df['quality_level'] = pd.cut(
        df['quality_score'], 
        bins=[0, 50, 200, 500, float('inf')], 
        labels=['ä½', 'ä¸­', 'é«˜', 'æœ€é«˜']
    )
    
    patterns = {}
    
    # å“è³ªãƒ¬ãƒ™ãƒ«åˆ¥çµ±è¨ˆ
    for level in ['ä½', 'ä¸­', 'é«˜', 'æœ€é«˜']:
        level_data = df[df['quality_level'] == level]
        if not level_data.empty:
            patterns[f'{level}å“è³ª'] = {
                'ä»¶æ•°': len(level_data),
                'å¹³å‡é•·ã•': level_data['prompt_length'].mean(),
                'å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³': level_data['reaction_count'].mean()
            }
    
    return patterns

def main():
    st.title("ğŸ¯ Civitai ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåˆ†æãƒ„ãƒ¼ãƒ«")
    st.markdown("åé›†ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆç´°åˆ†åŒ–ã¨ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚º")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        df = load_prompt_data()
    
    if df.empty:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åé›†ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚")
        st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹: " + DEFAULT_DB_PATH)
        return
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ - åŸºæœ¬æƒ…å ±
    st.sidebar.header("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦")
    st.sidebar.metric("ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", len(df))
    st.sidebar.metric("å¹³å‡å“è³ªã‚¹ã‚³ã‚¢", f"{df['quality_score'].mean():.1f}")
    st.sidebar.metric("å¹³å‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·", f"{df['prompt_length'].mean():.0f}")
    st.sidebar.metric("æœ€é«˜å“è³ªã‚¹ã‚³ã‚¢", f"{df['quality_score'].max():.0f}")
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ å“è³ªåˆ†æ", "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ†æ", "ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ", "ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°"])
    
    with tab1:
        st.header("å“è³ªã‚¹ã‚³ã‚¢åˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # å“è³ªã‚¹ã‚³ã‚¢åˆ†å¸ƒ
            fig_quality = px.histogram(
                df, 
                x='quality_score',
                nbins=50,
                title="å“è³ªã‚¹ã‚³ã‚¢åˆ†å¸ƒ",
                labels={'quality_score': 'å“è³ªã‚¹ã‚³ã‚¢', 'count': 'ä»¶æ•°'}
            )
            st.plotly_chart(fig_quality, use_container_width=True)
            
            # å“è³ªã¨é•·ã•ã®é–¢ä¿‚
            fig_scatter = px.scatter(
                df.sample(min(500, len(df))), 
                x='prompt_length', 
                y='quality_score',
                title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•· vs å“è³ªã‚¹ã‚³ã‚¢ï¼ˆã‚µãƒ³ãƒ—ãƒ«500ä»¶ï¼‰",
                labels={'prompt_length': 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·', 'quality_score': 'å“è³ªã‚¹ã‚³ã‚¢'},
                opacity=0.6
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        with col2:
            # å“è³ªãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
            df['quality_level'] = pd.cut(
                df['quality_score'], 
                bins=[0, 50, 200, 500, float('inf')], 
                labels=['ä½å“è³ª', 'ä¸­å“è³ª', 'é«˜å“è³ª', 'æœ€é«˜å“è³ª']
            )
            
            quality_counts = df['quality_level'].value_counts()
            fig_pie = px.pie(
                values=quality_counts.values,
                names=quality_counts.index,
                title="å“è³ªãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ"
            )
            st.plotly_chart(fig_pie, use_container_width=True)
            
            # å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
            st.subheader("å“è³ªãƒ‘ã‚¿ãƒ¼ãƒ³")
            patterns = analyze_quality_patterns(df)
            
            for level, stats in patterns.items():
                with st.expander(f"{level} ({stats['ä»¶æ•°']}ä»¶)"):
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.metric("å¹³å‡æ–‡å­—æ•°", f"{stats['å¹³å‡é•·ã•']:.0f}")
                    with col_b:
                        st.metric("å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³", f"{stats['å¹³å‡ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³']:.1f}")
    
    with tab2:
        st.header("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚«ãƒ†ã‚´ãƒªåˆ†æ")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
        sample_size = min(200, len(df))
        sample_df = df.head(sample_size).copy()
        
        with st.spinner(f"ä¸Šä½{sample_size}ä»¶ã‚’ã‚«ãƒ†ã‚´ãƒ©ã‚¤ã‚ºä¸­..."):
            categories = []
            confidences = []
            complexities = []
            complexity_scores = []
            
            for prompt in sample_df['full_prompt']:
                category, confidence = categorize_prompt_by_content(prompt)
                complexity, complexity_score = analyze_prompt_complexity(prompt)
                
                categories.append(category)
                confidences.append(confidence)
                complexities.append(complexity)
                complexity_scores.append(complexity_score)
            
            sample_df['category'] = categories
            sample_df['confidence'] = confidences
            sample_df['complexity'] = complexities
            sample_df['complexity_score'] = complexity_scores
        
        col1, col2 = st.columns(2)
        
        with col1:
            # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
            category_counts = sample_df['category'].value_counts()
            fig_cat = px.bar(
                x=category_counts.values,
                y=category_counts.index,
                orientation='h',
                title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ",
                labels={'x': 'ä»¶æ•°', 'y': 'ã‚«ãƒ†ã‚´ãƒª'}
            )
            st.plotly_chart(fig_cat, use_container_width=True)
            
            # è¤‡é›‘åº¦åˆ†å¸ƒ
            complexity_counts = sample_df['complexity'].value_counts()
            fig_comp = px.pie(
                values=complexity_counts.values,
                names=complexity_counts.index,
                title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¤‡é›‘åº¦åˆ†å¸ƒ"
            )
            st.plotly_chart(fig_comp, use_container_width=True)
        
        with col2:
            # ã‚«ãƒ†ã‚´ãƒªåˆ¥å“è³ªã‚¹ã‚³ã‚¢
            category_quality = sample_df.groupby('category')['quality_score'].agg(['mean', 'count']).reset_index()
            category_quality = category_quality[category_quality['count'] >= 3]  # 3ä»¶ä»¥ä¸Šã®ã‚«ãƒ†ã‚´ãƒªã®ã¿
            
            fig_cat_quality = px.bar(
                category_quality,
                x='category',
                y='mean',
                title="ã‚«ãƒ†ã‚´ãƒªåˆ¥å¹³å‡å“è³ªã‚¹ã‚³ã‚¢ï¼ˆ3ä»¶ä»¥ä¸Šï¼‰",
                labels={'mean': 'å¹³å‡å“è³ªã‚¹ã‚³ã‚¢', 'category': 'ã‚«ãƒ†ã‚´ãƒª'}
            )
            fig_cat_quality.update_xaxes(tickangle=45)
            st.plotly_chart(fig_cat_quality, use_container_width=True)
            
            # è¤‡é›‘åº¦ã¨å“è³ªã®é–¢ä¿‚
            complexity_quality = sample_df.groupby('complexity')['quality_score'].mean().reset_index()
            fig_comp_quality = px.bar(
                complexity_quality,
                x='complexity',
                y='quality_score',
                title="è¤‡é›‘åº¦åˆ¥å¹³å‡å“è³ªã‚¹ã‚³ã‚¢",
                labels={'quality_score': 'å¹³å‡å“è³ªã‚¹ã‚³ã‚¢', 'complexity': 'è¤‡é›‘åº¦'}
            )
            st.plotly_chart(fig_comp_quality, use_container_width=True)
        
        # ã‚«ãƒ†ã‚´ãƒªè©³ç´°
        st.subheader("ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°")
        
        selected_category = st.selectbox(
            "è©³ç´°è¡¨ç¤ºã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ:",
            sample_df['category'].unique()
        )
        
        category_data = sample_df[sample_df['category'] == selected_category]
        
        if not category_data.empty:
            st.write(f"**{selected_category}** ({len(category_data)}ä»¶)")
            
            # çµ±è¨ˆæƒ…å ±
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("å¹³å‡å“è³ªã‚¹ã‚³ã‚¢", f"{category_data['quality_score'].mean():.1f}")
            with col_b:
                st.metric("å¹³å‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·", f"{category_data['prompt_length'].mean():.0f}")
            with col_c:
                st.metric("å¹³å‡ä¿¡é ¼åº¦", f"{category_data['confidence'].mean():.2f}")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¡¨ç¤º
            st.subheader("ã‚µãƒ³ãƒ—ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¸Šä½5ä»¶ï¼‰")
            top_samples = category_data.nlargest(5, 'quality_score')
            
            for idx, (_, row) in enumerate(top_samples.iterrows(), 1):
                quality_class = (
                    "quality-high" if row['quality_score'] > 300 
                    else "quality-medium" if row['quality_score'] > 100 
                    else "quality-low"
                )
                
                st.markdown(f"""
                <div class="prompt-card">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 0.5rem;">
                        <strong>#{idx}</strong>
                        <span class="{quality_class}">å“è³ª: {row['quality_score']:.0f}</span>
                    </div>
                    <div style="margin-bottom: 0.5rem;">
                        <strong>è¤‡é›‘åº¦:</strong> {row['complexity']} ({row['complexity_score']:.1f})
                    </div>
                    <div style="font-size: 0.9rem; color: #666;">
                        {row['full_prompt'][:200]}{"..." if len(row['full_prompt']) > 200 else ""}
                    </div>
                </div>
                """, unsafe_allow_html=True)
    
    with tab3:
        st.header("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")
        
        with st.spinner("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’åˆ†æä¸­..."):
            keywords = extract_top_keywords(df, min_frequency=10, max_keywords=100)
        
        if keywords:
            col1, col2 = st.columns(2)
            
            with col1:
                # é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP30
                top_30_keywords = dict(list(keywords.items())[:30])
                keyword_df = pd.DataFrame(list(top_30_keywords.items()), columns=['ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰', 'å‡ºç¾å›æ•°'])
                
                fig_keywords = px.bar(
                    keyword_df,
                    x='å‡ºç¾å›æ•°',
                    y='ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰',
                    orientation='h',
                    title="é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP30",
                    labels={'å‡ºç¾å›æ•°': 'å‡ºç¾å›æ•°', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'}
                )
                fig_keywords.update_layout(height=800)
                st.plotly_chart(fig_keywords, use_container_width=True)
            
            with col2:
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆ
                st.subheader("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµ±è¨ˆ")
                
                col_stat1, col_stat2 = st.columns(2)
                with col_stat1:
                    st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°", len(keywords))
                    st.metric("ç·å‡ºç¾å›æ•°", sum(keywords.values()))
                
                with col_stat2:
                    st.metric("å¹³å‡å‡ºç¾å›æ•°", f"{np.mean(list(keywords.values())):.1f}")
                    st.metric("æœ€é«˜å‡ºç¾å›æ•°", max(keywords.values()))
                
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é »åº¦åˆ†å¸ƒ
                freq_values = list(keywords.values())
                fig_freq_dist = px.histogram(
                    x=freq_values,
                    nbins=20,
                    title="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é »åº¦åˆ†å¸ƒ",
                    labels={'x': 'å‡ºç¾å›æ•°', 'y': 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°'}
                )
                st.plotly_chart(fig_freq_dist, use_container_width=True)
                
                # ãƒˆãƒƒãƒ—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è©³ç´°
                st.subheader("ãƒˆãƒƒãƒ—10ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
                top_10 = list(keywords.items())[:10]
                
                for i, (keyword, count) in enumerate(top_10, 1):
                    percentage = (count / len(df)) * 100
                    st.write(f"{i}. **{keyword}** - {count}å› ({percentage:.1f}%)")
        
        else:
            st.warning("ååˆ†ãªé »åº¦ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    with tab4:
        st.header("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°æ¤œç´¢")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            min_quality = st.slider("æœ€å°å“è³ªã‚¹ã‚³ã‚¢", 0, int(df['quality_score'].max()), 0)
        
        with col2:
            max_quality = st.slider("æœ€å¤§å“è³ªã‚¹ã‚³ã‚¢", 0, int(df['quality_score'].max()), int(df['quality_score'].max()))
        
        with col3:
            min_length = st.slider("æœ€å°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·", 0, int(df['prompt_length'].max()), 0)
        
        with col4:
            sort_by = st.selectbox("ä¸¦ã³é †", ['å“è³ªã‚¹ã‚³ã‚¢', 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·', 'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°'], index=0)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        search_keyword = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã§æ¤œç´¢ï¼‰")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        filtered_df = df[
            (df['quality_score'] >= min_quality) & 
            (df['quality_score'] <= max_quality) &
            (df['prompt_length'] >= min_length)
        ]
        
        if search_keyword:
            filtered_df = filtered_df[
                filtered_df['full_prompt'].str.contains(search_keyword, case=False, na=False)
            ]
        
        # ã‚½ãƒ¼ãƒˆ
        sort_columns = {
            'å“è³ªã‚¹ã‚³ã‚¢': 'quality_score',
            'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·': 'prompt_length', 
            'ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°': 'reaction_count'
        }
        filtered_df = filtered_df.sort_values(sort_columns[sort_by], ascending=False)
        
        st.subheader(f"æ¤œç´¢çµæœ: {len(filtered_df)} ä»¶")
        
        if len(filtered_df) > 0:
            # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
            items_per_page = 10
            total_pages = max(1, (len(filtered_df) - 1) // items_per_page + 1)
            
            col_page1, col_page2 = st.columns([1, 4])
            with col_page1:
                current_page = st.selectbox("ãƒšãƒ¼ã‚¸", range(1, total_pages + 1)) - 1
            
            start_idx = current_page * items_per_page
            end_idx = min(start_idx + items_per_page, len(filtered_df))
            page_data = filtered_df.iloc[start_idx:end_idx]
            
            # çµæœè¡¨ç¤º
            for idx, (_, row) in enumerate(page_data.iterrows(), start_idx + 1):
                quality_class = (
                    "quality-high" if row['quality_score'] > 300 
                    else "quality-medium" if row['quality_score'] > 100 
                    else "quality-low"
                )
                
                with st.expander(f"#{idx} | ID: {row['civitai_id']} | å“è³ª: {row['quality_score']:.0f} | é•·ã•: {row['prompt_length']:.0f}"):
                    col_detail1, col_detail2 = st.columns([3, 1])
                    
                    with col_detail1:
                        st.text_area(
                            "ãƒ•ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:", 
                            row['full_prompt'], 
                            height=120,
                            key=f"prompt_{idx}"
                        )
                        
                        if pd.notna(row['negative_prompt']) and str(row['negative_prompt']).strip():
                            st.text_area(
                                "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:",
                                row['negative_prompt'],
                                height=80,
                                key=f"neg_prompt_{idx}"
                            )
                    
                    with col_detail2:
                        st.metric("å“è³ªã‚¹ã‚³ã‚¢", f"{row['quality_score']:.0f}")
                        st.metric("ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°", f"{row['reaction_count']:.0f}")
                        st.metric("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·", f"{row['prompt_length']:.0f}")
                        
                        if pd.notna(row['model_name']):
                            st.info(f"**ãƒ¢ãƒ‡ãƒ«:** {row['model_name']}")
                        
                        if pd.notna(row['collected_at']):
                            st.caption(f"åé›†æ—¥: {row['collected_at']}")
            
            # ãƒšãƒ¼ã‚¸æƒ…å ±
            st.caption(f"ãƒšãƒ¼ã‚¸ {current_page + 1} / {total_pages} | è¡¨ç¤ºä¸­: {start_idx + 1}-{end_idx} / {len(filtered_df)}ä»¶")
        
        else:
            st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

if __name__ == "__main__":
    main()