#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆç®¡ç†ãƒ»å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 

åé›†ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆåˆ†æã¨å‚¾å‘æŠŠæ¡ã®ãŸã‚ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½
"""

import sqlite3
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from datetime import datetime, timedelta
import json
import re
from collections import Counter

class StatisticsManager:
    def __init__(self, db_path: str = "data/civitai_dataset.db"):
        self.db_path = db_path

    def get_connection(self):
        return sqlite3.connect(self.db_path)

    def get_basic_stats(self) -> dict:
        """åŸºæœ¬çµ±è¨ˆæƒ…å ±å–å¾—"""
        with self.get_connection() as conn:
            # åŸºæœ¬ã‚«ã‚¦ãƒ³ãƒˆ
            basic_query = """
                SELECT
                    COUNT(*) as total_prompts,
                    COUNT(DISTINCT model_name) as unique_models,
                    COUNT(DISTINCT model_version_id) as unique_versions,
                    AVG(quality_score) as avg_quality,
                    AVG(reaction_count) as avg_reactions,
                    AVG(prompt_length) as avg_length,
                    MIN(collected_at) as first_collected,
                    MAX(collected_at) as last_collected
                FROM civitai_prompts
            """

            basic_df = pd.read_sql_query(basic_query, conn)

            # å“è³ªåˆ†å¸ƒ
            quality_query = """
                SELECT
                    CASE
                        WHEN quality_score >= 500 THEN 'Very High (500+)'
                        WHEN quality_score >= 100 THEN 'High (100-499)'
                        WHEN quality_score >= 50 THEN 'Medium (50-99)'
                        WHEN quality_score >= 10 THEN 'Low (10-49)'
                        ELSE 'Very Low (0-9)'
                    END as quality_tier,
                    COUNT(*) as count
                FROM civitai_prompts
                GROUP BY quality_tier
                ORDER BY MIN(quality_score) DESC
            """

            quality_df = pd.read_sql_query(quality_query, conn)

            return {
                'basic': basic_df.iloc[0].to_dict(),
                'quality_distribution': quality_df
            }

    def analyze_prompt_trends(self) -> dict:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        with self.get_connection() as conn:
            # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
            timeline_query = """
                SELECT
                    DATE(collected_at) as collection_date,
                    COUNT(*) as daily_count,
                    AVG(quality_score) as daily_avg_quality
                FROM civitai_prompts
                WHERE collected_at IS NOT NULL
                GROUP BY DATE(collected_at)
                ORDER BY collection_date
            """

            timeline_df = pd.read_sql_query(timeline_query, conn)

            # é•·ã•åˆ†å¸ƒ
            length_query = """
                SELECT
                    CASE
                        WHEN prompt_length >= 1000 THEN 'Very Long (1000+)'
                        WHEN prompt_length >= 500 THEN 'Long (500-999)'
                        WHEN prompt_length >= 200 THEN 'Medium (200-499)'
                        WHEN prompt_length >= 50 THEN 'Short (50-199)'
                        ELSE 'Very Short (0-49)'
                    END as length_category,
                    COUNT(*) as count,
                    AVG(quality_score) as avg_quality
                FROM civitai_prompts
                GROUP BY length_category
                ORDER BY MIN(prompt_length)
            """

            length_df = pd.read_sql_query(length_query, conn)

            return {
                'timeline': timeline_df,
                'length_distribution': length_df
            }

    def analyze_model_performance(self) -> dict:
        """ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ"""
        with self.get_connection() as conn:
            model_query = """
                SELECT
                    model_name,
                    COUNT(*) as prompt_count,
                    AVG(quality_score) as avg_quality,
                    MAX(quality_score) as max_quality,
                    AVG(reaction_count) as avg_reactions,
                    AVG(prompt_length) as avg_length
                FROM civitai_prompts
                WHERE model_name IS NOT NULL
                GROUP BY model_name
                HAVING prompt_count >= 5
                ORDER BY avg_quality DESC
            """

            model_df = pd.read_sql_query(model_query, conn)

            return {'models': model_df}

    def extract_keyword_trends(self) -> dict:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        with self.get_connection() as conn:
            # å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå–å¾—
            cursor = conn.cursor()
            cursor.execute("SELECT full_prompt, quality_score FROM civitai_prompts WHERE full_prompt IS NOT NULL")
            prompts_data = cursor.fetchall()

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ»åˆ†æ
            keyword_stats = Counter()
            quality_by_keyword = {}

            # ä¸€èˆ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å®šç¾©
            target_keywords = [
                'masterpiece', 'best quality', 'high quality', 'detailed', 'ultra detailed',
                'realistic', 'photorealistic', 'anime', 'portrait', 'landscape',
                '8k', '4k', 'high resolution', 'sharp', 'focus', 'depth of field',
                'lighting', 'cinematic', 'dramatic', 'beautiful', 'stunning',
                'girl', 'woman', 'man', 'boy', 'character', 'background'
            ]

            for prompt, quality in prompts_data:
                if not prompt:
                    continue

                prompt_lower = prompt.lower()
                for keyword in target_keywords:
                    if keyword in prompt_lower:
                        keyword_stats[keyword] += 1
                        if keyword not in quality_by_keyword:
                            quality_by_keyword[keyword] = []
                        quality_by_keyword[keyword].append(quality)

            # å“è³ªçµ±è¨ˆè¨ˆç®—
            keyword_quality_stats = {}
            for keyword, qualities in quality_by_keyword.items():
                if len(qualities) >= 5:  # 5ä»¶ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‚‚ã®ã®ã¿
                    keyword_quality_stats[keyword] = {
                        'count': len(qualities),
                        'avg_quality': sum(qualities) / len(qualities),
                        'max_quality': max(qualities),
                        'min_quality': min(qualities)
                    }

            return {
                'keyword_frequency': dict(keyword_stats.most_common(20)),
                'keyword_quality': keyword_quality_stats
            }

    def generate_recommendations(self) -> dict:
        """ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæ¨å¥¨äº‹é …ç”Ÿæˆ"""
        stats = self.get_basic_stats()
        trends = self.analyze_prompt_trends()
        models = self.analyze_model_performance()
        keywords = self.extract_keyword_trends()

        recommendations = {
            'collection_strategy': [],
            'prompt_optimization': [],
            'model_selection': [],
            'data_quality': []
        }

        # åé›†æˆ¦ç•¥æ¨å¥¨
        avg_quality = stats['basic']['avg_quality']
        if avg_quality < 50:
            recommendations['collection_strategy'].append(
                "å¹³å‡å“è³ªãŒä½ã‚ï¼ˆ{:.1f}ï¼‰ã€‚ã‚ˆã‚Šé«˜å“è³ªãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åé›†ã‚’é‡ç‚¹åŒ–".format(avg_quality)
            )

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–æ¨å¥¨
        best_keywords = sorted(keywords['keyword_quality'].items(),
                              key=lambda x: x[1]['avg_quality'], reverse=True)[:5]

        recommendations['prompt_optimization'].append(
            f"é«˜å“è³ªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«é »å‡ºã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {[k[0] for k in best_keywords]}"
        )

        # ãƒ¢ãƒ‡ãƒ«é¸æŠæ¨å¥¨
        if not models['models'].empty:
            top_model = models['models'].iloc[0]
            recommendations['model_selection'].append(
                f"æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«: {top_model['model_name']} (å¹³å‡å“è³ª: {top_model['avg_quality']:.1f})"
            )

        # ãƒ‡ãƒ¼ã‚¿å“è³ªæ¨å¥¨
        total_prompts = stats['basic']['total_prompts']
        if total_prompts < 1000:
            recommendations['data_quality'].append(
                f"ãƒ‡ãƒ¼ã‚¿é‡ãŒå°‘ãªã‚ï¼ˆ{total_prompts}ä»¶ï¼‰ã€‚ã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒ«åé›†ã‚’æ¨å¥¨"
            )

        return recommendations

def create_statistics_dashboard():
    """Streamlitçµ±è¨ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    st.set_page_config(page_title="CivitAI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµ±è¨ˆ", layout="wide")

    st.title("ğŸ“Š CivitAI ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ‡ãƒ¼ã‚¿çµ±è¨ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    # çµ±è¨ˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
    stats_manager = StatisticsManager()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.header("ğŸ“‹ åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³")
    show_basic = st.sidebar.checkbox("åŸºæœ¬çµ±è¨ˆ", value=True)
    show_trends = st.sidebar.checkbox("ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ", value=True)
    show_models = st.sidebar.checkbox("ãƒ¢ãƒ‡ãƒ«åˆ†æ", value=True)
    show_keywords = st.sidebar.checkbox("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ", value=True)
    show_recommendations = st.sidebar.checkbox("æ¨å¥¨äº‹é …", value=True)

    # ãƒ¡ã‚¤ãƒ³è¡¨ç¤º
    if show_basic:
        st.header("ğŸ¯ åŸºæœ¬çµ±è¨ˆ")

        try:
            basic_stats = stats_manager.get_basic_stats()
            basic = basic_stats['basic']

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("ç·ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°", f"{basic['total_prompts']:,}")
            with col2:
                st.metric("ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ¢ãƒ‡ãƒ«æ•°", f"{basic['unique_models']:,}")
            with col3:
                st.metric("å¹³å‡å“è³ªã‚¹ã‚³ã‚¢", f"{basic['avg_quality']:.1f}")
            with col4:
                st.metric("å¹³å‡æ–‡å­—æ•°", f"{basic['avg_length']:.0f}")

            # å“è³ªåˆ†å¸ƒ
            quality_dist = basic_stats['quality_distribution']
            fig_quality = px.pie(quality_dist, values='count', names='quality_tier',
                               title="å“è³ªã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
            st.plotly_chart(fig_quality, use_container_width=True)

        except Exception as e:
            st.error(f"åŸºæœ¬çµ±è¨ˆã®å–å¾—ã«å¤±æ•—: {str(e)}")

    if show_trends:
        st.header("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")

        try:
            trend_stats = stats_manager.analyze_prompt_trends()

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
            if not trend_stats['timeline'].empty:
                timeline_df = trend_stats['timeline']
                timeline_df['collection_date'] = pd.to_datetime(timeline_df['collection_date'])

                fig_timeline = px.line(timeline_df, x='collection_date', y='daily_count',
                                     title="æ—¥åˆ¥åé›†æ•°æ¨ç§»")
                st.plotly_chart(fig_timeline, use_container_width=True)

            # é•·ã•åˆ†å¸ƒ
            length_dist = trend_stats['length_distribution']
            fig_length = px.bar(length_dist, x='length_category', y='count',
                              color='avg_quality', title="ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·ã•åˆ†å¸ƒ")
            st.plotly_chart(fig_length, use_container_width=True)

        except Exception as e:
            st.error(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã«å¤±æ•—: {str(e)}")

    if show_models:
        st.header("ğŸ¤– ãƒ¢ãƒ‡ãƒ«æ€§èƒ½åˆ†æ")

        try:
            model_stats = stats_manager.analyze_model_performance()
            models_df = model_stats['models']

            if not models_df.empty:
                # ãƒˆãƒƒãƒ—10ãƒ¢ãƒ‡ãƒ«è¡¨ç¤º
                st.subheader("ãƒˆãƒƒãƒ—10ãƒ¢ãƒ‡ãƒ«ï¼ˆå¹³å‡å“è³ªé †ï¼‰")
                top_models = models_df.head(10)

                fig_models = px.scatter(top_models, x='prompt_count', y='avg_quality',
                                      size='max_quality', hover_name='model_name',
                                      title="ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ•£å¸ƒå›³")
                st.plotly_chart(fig_models, use_container_width=True)

                # è©³ç´°ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
                st.dataframe(top_models, use_container_width=True)
            else:
                st.warning("ååˆ†ãªãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«åˆ†æã«å¤±æ•—: {str(e)}")

    if show_keywords:
        st.header("ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ")

        try:
            keyword_stats = stats_manager.extract_keyword_trends()

            # é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            st.subheader("é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ TOP20")
            freq_data = keyword_stats['keyword_frequency']
            freq_df = pd.DataFrame(list(freq_data.items()), columns=['keyword', 'frequency'])

            fig_freq = px.bar(freq_df.head(15), x='frequency', y='keyword',
                            orientation='h', title="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å‡ºç¾é »åº¦")
            st.plotly_chart(fig_freq, use_container_width=True)

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªç›¸é–¢
            st.subheader("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å“è³ªç›¸é–¢")
            quality_data = keyword_stats['keyword_quality']
            quality_df = pd.DataFrame.from_dict(quality_data, orient='index')

            if not quality_df.empty:
                quality_df = quality_df.reset_index().rename(columns={'index': 'keyword'})
                quality_df = quality_df.sort_values('avg_quality', ascending=False).head(15)

                fig_quality_kw = px.scatter(quality_df, x='count', y='avg_quality',
                                          size='max_quality', hover_name='keyword',
                                          title="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ä½¿ç”¨é »åº¦ vs å¹³å‡å“è³ª")
                st.plotly_chart(fig_quality_kw, use_container_width=True)

        except Exception as e:
            st.error(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã«å¤±æ•—: {str(e)}")

    if show_recommendations:
        st.header("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³æ¨å¥¨äº‹é …")

        try:
            recommendations = stats_manager.generate_recommendations()

            for category, items in recommendations.items():
                if items:
                    st.subheader(category.replace('_', ' ').title())
                    for item in items:
                        st.write(f"â€¢ {item}")

        except Exception as e:
            st.error(f"æ¨å¥¨äº‹é …ç”Ÿæˆã«å¤±æ•—: {str(e)}")

    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    st.sidebar.markdown("---")
    st.sidebar.info("ğŸ’¡ ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯åé›†ãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æã—ã€ComfyUIç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã®æ´å¯Ÿã‚’æä¾›ã—ã¾ã™ã€‚")

if __name__ == "__main__":
    create_statistics_dashboard()
